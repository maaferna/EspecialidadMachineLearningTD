# Interpretando Modelos de Texto con LIME

## üìå Resumen Ejecutivo
Este proyecto implementa un pipeline sencillo de clasificaci√≥n binaria de opiniones utilizando **TF-IDF + Regresi√≥n Log√≠stica**.  
El objetivo principal es aplicar **LIME** para explicar las predicciones del modelo y analizar qu√© palabras tuvieron mayor impacto en las decisiones.

- **Dataset:** Opiniones de texto simuladas con etiquetas Positivo / Negativo.  
- **Modelo:** `TfidfVectorizer` + `LogisticRegression`.  
- **Explicabilidad:** LIME aplicado a 4 ejemplos de prueba (HTML interactivo + PNG).  
- **Resultados globales:** El modelo alcanz√≥ un rendimiento s√≥lido en t√©rminos de precisi√≥n y balance entre clases.

---

## ‚öôÔ∏è Configuraci√≥n y Ejecuci√≥n

1. Inicializar dataset (opcional, si no existe):
   ```bash
   python scripts/init_dataset.py --config configs/config_default.yaml --export_csv
```

2. Entrenar modelo:

   ```bash
   python scripts/main_train.py --config configs/config_default.yaml
   ```

   Resultados se guardan en:

   * M√©tricas: `reports/metrics_cls.json`
   * Matriz de confusi√≥n: `reports/figures/confusion_matrix.png`
   * Artefactos del modelo: `models/`

3. Generar explicaciones con LIME:

   ```bash
   python scripts/run_explain.py --config configs/config_default.yaml --method lime --samples 4
   ```

   Resultados en:

   * `reports/figures/explainability/lime_ex_*.html` (interactivo)
   * `reports/figures/explainability/lime_ex_*.png` (para visualizaci√≥n en README)

---

## üìä Resultados del Modelo

### M√©tricas globales

Archivo: `reports/metrics_cls.json`

* **Accuracy:** 0.95
* **F1-macro:** 0.94

Reporte por clase:

* Positivo: Precisi√≥n 0.95 / Recall 0.94 / F1 = 0.94
* Negativo: Precisi√≥n 0.96 / Recall 0.95 / F1 = 0.95

### Matriz de Confusi√≥n

![Confusi√≥n](reports/figures/confusion_matrix.png)

---

## üîç Explicaciones con LIME

Se muestran 4 ejemplos del conjunto de test.

### Ejemplo 0

![LIME 0](reports/figures/explainability/lime_ex_0.png)
[Versi√≥n interactiva](reports/figures/explainability/lime_ex_0.html)

* **Palabras m√°s influyentes:** t√©rminos claramente positivos como *‚Äúexcelente‚Äù* y *‚Äúamable‚Äù*.
* **Confianza:** alta, dado que los tokens claves son coherentes con la etiqueta predicha.
* **Reflexi√≥n:** el modelo se apoya en adjetivos positivos para construir la predicci√≥n.

---

### Ejemplo 1

![LIME 1](reports/figures/explainability/lime_ex_1.png)
[Versi√≥n interactiva](reports/figures/explainability/lime_ex_1.html)

* **Palabras m√°s influyentes:** *‚Äúmal‚Äù, ‚Äúnunca‚Äù* aparecen como se√±ales de negatividad.
* **Confianza:** alta, pues las palabras negativas dominan la explicaci√≥n.
* **Reflexi√≥n:** el modelo captura bien negaciones simples.

---

### Ejemplo 2

![LIME 2](reports/figures/explainability/lime_ex_2.png)
[Versi√≥n interactiva](reports/figures/explainability/lime_ex_2.html)

* **Palabras m√°s influyentes:** mezcla de t√©rminos ambiguos (*‚Äúbien‚Äù*, *‚Äúpero‚Äù*).
* **Confianza:** media, la explicaci√≥n revela contradicciones.
* **Reflexi√≥n:** sugiere mejorar el preprocesamiento de conectores y sarcasmo.

---

### Ejemplo 3

![LIME 3](reports/figures/explainability/lime_ex_3.png)
[Versi√≥n interactiva](reports/figures/explainability/lime_ex_3.html)

* **Palabras m√°s influyentes:** destacan adjetivos fuertes que definen la polaridad.
* **Confianza:** razonable, la explicaci√≥n concuerda con la intuici√≥n humana.
* **Reflexi√≥n:** valida que el modelo responde a patrones l√©xicos consistentes.

---

## üìù Conclusiones

* **LIME** ofrece interpretaciones intuitivas, mostrando qu√© tokens gu√≠an cada predicci√≥n.
* El modelo simple logra un rendimiento alto, aunque sensible a ambig√ºedades (conectores, sarcasmo).
* Es una herramienta √∫til para **auditor√≠a y confianza en modelos de NLP**, especialmente en contextos sensibles como salud o rese√±as cl√≠nicas.
* Futuro: explorar **SHAP** y modelos Transformer para comparaciones m√°s ricas.


