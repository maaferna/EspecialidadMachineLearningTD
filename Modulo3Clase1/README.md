# ğŸ“Š RegresiÃ³n Lineal con Ãlgebra Matricial

Este proyecto implementa una soluciÃ³n de regresiÃ³n lineal simple en Python utilizando **Ã¡lgebra matricial**. La implementaciÃ³n aplica directamente la fÃ³rmula matemÃ¡tica:

\[
\boldsymbol{\beta} = (X^T X)^{-1} X^T y
\]

donde:

- `X` es la **matriz de diseÃ±o** (columna de unos + columna de caracterÃ­sticas)
- `y` es el **vector de valores observados**
- `Î²` es el **vector de parÃ¡metros estimados** (intercepto y pendiente)

---

## ğŸ¯ Objetivo

Resolver la regresiÃ³n lineal sin utilizar librerÃ­as de ML como `scikit-learn`, sino mediante manipulaciÃ³n de vectores y matrices con `NumPy`. Este enfoque permite:

- Comprender los fundamentos de muchos algoritmos de aprendizaje supervisado
- Visualizar paso a paso el ajuste de un modelo

---

## ğŸ§  Ãlgebra Matricial en AcciÃ³n

### Dimensiones involucradas:

- `X.shape`: (100, 2) â†’ 100 muestras, 2 columnas (bias + feature)
- `X.T.shape`: (2, 100)
- `X.T @ X.shape`: (2, 2)
- `Î².shape`: (2, 1)

Estas formas confirman que la multiplicaciÃ³n matricial estÃ¡ correctamente definida, y que se obtiene un vector de dos parÃ¡metros: la ordenada al origen (**intercepto**) y la pendiente (**coeficiente de regresiÃ³n**).

---

## ğŸ“ˆ Resultado Visual

El modelo ajustado genera una lÃ­nea que minimiza el error cuadrÃ¡tico entre las predicciones y los valores reales, como se muestra en el siguiente grÃ¡fico:

![GrÃ¡fico de regresiÃ³n](./outputs/grafico_resultado.png)

---

## ğŸ“Œ Estructura del CÃ³digo

- `generar_datos(n=100)`  
  Genera 100 datos aleatorios con una relaciÃ³n lineal `y = 4 + 3x + ruido`.

- `ajustar_modelo(x, y)`  
  Aplica la fÃ³rmula matricial para estimar `Î²`.

- `graficar_resultado(x, y, beta)`  
  Dibuja los datos y la lÃ­nea ajustada.

Cada funciÃ³n estÃ¡ documentada con docstrings, y el cÃ³digo contiene `print()` para mostrar las formas de las matrices involucradas, facilitando el anÃ¡lisis conceptual.

---

## ğŸ§© Â¿Por quÃ© es importante este enfoque?

La regresiÃ³n lineal mediante Ã¡lgebra matricial es la base de:

- RegresiÃ³n mÃºltiple
- Algoritmos de optimizaciÃ³n (gradiente descendente)
- Redes neuronales (ajuste de pesos)
- MÃ©todos estadÃ­sticos avanzados

Entender este proceso sin utilizar automatismos permite dominar los fundamentos matemÃ¡ticos que sostienen modelos mÃ¡s complejos.

---

## âœ… ConclusiÃ³n

Este proyecto demuestra cÃ³mo resolver una tarea fundamental de aprendizaje supervisado de manera explÃ­cita, clara y reproducible. Es ideal como ejercicio introductorio a Machine Learning desde una perspectiva matemÃ¡tica.

