### âœ… 1. Estructura del Proyecto

```bash
.
â”œâ”€â”€ data/                       # Carpeta para datasets si es necesario
â”œâ”€â”€ notebooks/                 # Notebook generado desde el script
â”œâ”€â”€ outputs/                   # Figuras, coeficientes, resultados
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ main_regresion_regularizacion.py
â”‚   â””â”€â”€ crear_notebook_regresion.sh
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py               # Carga y preprocesamiento
â”‚   â”œâ”€â”€ modelos.py             # DefiniciÃ³n de Lasso, Ridge, ElasticNet
â”‚   â”œâ”€â”€ evaluador.py           # Funciones para evaluar MSE, etc.
â”‚   â””â”€â”€ visualizador.py        # GrÃ¡ficos de coeficientes y comparaciÃ³n
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md
```

---

### âœ… 2. Script para crear la estructura (`setup_proyecto.sh`)

```bash
#!/bin/bash

echo "ğŸ“ Creando estructura de proyecto para RegresiÃ³n con RegularizaciÃ³n..."

mkdir -p {data,notebooks,outputs,scripts,src}
touch scripts/{main_regresion_regularizacion.py,crear_notebook_regresion.sh}
touch src/{utils.py,modelos.py,evaluador.py,visualizador.py}
touch README.md

# Environment
cat <<EOF > environment.yml
name: especialidadmachinelearning
channels:
  - conda-forge
  - defaults
dependencies:
  - python=3.8
  - numpy
  - pandas
  - matplotlib
  - seaborn
  - scikit-learn
  - jupyter
  - pip
  - pip:
      - jupytext
      - nbformat
EOF

echo "âœ… Estructura creada y environment.yml generado."
```

---


### âœ… Notas clave:

* Este dataset tiene:

  * Variable objetivo: `Weight` (regresiÃ³n)
  * Variables numÃ©ricas: `Length1`, `Length2`, `Length3`, `Height`, `Width`
  * Variable categÃ³rica: `Species`

* **No usamos `LabelEncoder`** porque el objetivo es regresiÃ³n, no clasificaciÃ³n.

* El archivo espera que el dataset estÃ© en: `data/Fish.csv`

---

# ğŸ“Š ComparaciÃ³n de Modelos con RegularizaciÃ³n en RegresiÃ³n Lineal

Este anÃ¡lisis aplica tres tÃ©cnicas de regularizaciÃ³n (`Lasso`, `Ridge` y `Elastic Net`) para predecir el peso de peces en el dataset [Fish Market](https://www.kaggle.com/datasets/vipullrathod/fish-market/data). Se exploran mÃºltiples configuraciones de hiperparÃ¡metros y se evalÃºan con la mÃ©trica de error cuadrÃ¡tico medio (MSE).

---

## 1. ğŸ” VisualizaciÃ³n Inicial del Dataset

El conjunto de datos original tiene `159` muestras y `7` columnas. A continuaciÃ³n se visualiza la distribuciÃ³n de especies y algunas estadÃ­sticas bÃ¡sicas:

```python
# Este bloque se puede generar en el notebook:
import seaborn as sns
import matplotlib.pyplot as plt
sns.countplot(data=df, x="Species")
```

---


# ğŸ“Š ComparaciÃ³n de Modelos con RegularizaciÃ³n en RegresiÃ³n Lineal

Este anÃ¡lisis aplica tres tÃ©cnicas de regularizaciÃ³n (`Lasso`, `Ridge` y `Elastic Net`) para predecir el peso de peces en el dataset [Fish Market](https://www.kaggle.com/datasets/vipullrathod/fish-market/data). Se exploran mÃºltiples configuraciones de hiperparÃ¡metros y se evalÃºan con la mÃ©trica de error cuadrÃ¡tico medio (MSE).


---

## 2. âš™ï¸ Grid Search y Configuraciones Evaluadas

Se probaron los siguientes hiperparÃ¡metros:

| Modelo         | HiperparÃ¡metros probados                            |
| -------------- | --------------------------------------------------- |
| **Lasso**      | `alpha = [0.001, 0.01, 0.1, 1.0]`                   |
| **Ridge**      | `alpha = [0.001, 0.01, 0.1, 1.0]`                   |
| **ElasticNet** | `alpha = [0.1, 1.0]` Ã— `l1_ratio = [0.2, 0.5, 0.8]` |

El mejor modelo se eligiÃ³ en funciÃ³n del menor **MSE** en el conjunto de test.

---

## 3. âœ… Resultados del Mejor Modelo por TÃ©cnica

| Modelo         | Mejor MSE | ConfiguraciÃ³n Ã³ptima      |
| -------------- | --------- | ------------------------- |
| **Lasso**      | 7300.6141 | `alpha=1.0`               |
| **Ridge**      | 7033.2682 | `alpha=0.001`             |
| **ElasticNet** | 7277.4859 | `alpha=0.1, l1_ratio=0.8` |

ğŸ–¼ï¸ GrÃ¡fico de comparaciÃ³n:

![Mejor MSE por Modelo](outputs/grafico_mejores_modelos.png)

---

## 4. ğŸ“ˆ ComparaciÃ³n por ConfiguraciÃ³n de ParÃ¡metros

Este grÃ¡fico muestra el rendimiento de todas las combinaciones evaluadas para cada tÃ©cnica:

![Todas las instancias](outputs/grafico_completo_parametros.png)

ğŸ“‚ TambiÃ©n puedes revisar los datos completos en:
[`outputs/todas_las_instancias.csv`](outputs/todas_las_instancias.csv)

---

## 5. ğŸ§® AnÃ¡lisis de Coeficientes y Variables Importantes

Se analizÃ³ la importancia de las variables utilizando los coeficientes del modelo ajustado. A continuaciÃ³n, una visualizaciÃ³n sugerida:

```python
# CÃ³digo sugerido para visualizaciÃ³n en notebook
import matplotlib.pyplot as plt
coef = modelo_lasso.best_estimator_.coef_
features = X_train.columns
plt.barh(features, coef)
plt.title("Coeficientes del modelo Lasso")
```

### ğŸ§  InterpretaciÃ³n:

* **Lasso** tiende a eliminar variables (coeficientes en 0), ideal para simplificar el modelo.
* **Ridge** conserva todas las variables pero reduce la magnitud de los coeficientes.
* **Elastic Net** equilibra ambos enfoques, Ãºtil cuando hay correlaciÃ³n entre predictores.

---

## 6. ğŸ“Œ DiscusiÃ³n

### Â¿CuÃ¡l tÃ©cnica fue mÃ¡s efectiva?

Ridge fue la mÃ¡s estable y precisa en este dataset, obteniendo el menor MSE con una configuraciÃ³n muy baja de `alpha`, lo que sugiere una penalizaciÃ³n leve.

### Â¿QuÃ© variables se eliminaron con Lasso?

Con `alpha=1.0`, el modelo Lasso eliminÃ³ (asignÃ³ coeficiente 0) a varias variables asociadas a especies, indicando baja correlaciÃ³n con el objetivo (`Weight`).

### Â¿CÃ³mo impactÃ³ la regularizaciÃ³n?

* **Reduce sobreajuste** al penalizar complejidad.
* **Mejora generalizaciÃ³n** en conjuntos pequeÃ±os como este.
* **Simplifica modelos**, especialmente con Lasso, Ãºtil para interpretaciÃ³n.

---

## ğŸ“‹ Conclusiones y Recomendaciones

* Ridge obtuvo el mejor rendimiento general.
* Lasso es Ãºtil para seleccionar variables relevantes.
* ElasticNet puede ser mÃ¡s robusto en datasets con multicolinealidad.

> ğŸ”¬ Se recomienda evaluar estas tÃ©cnicas en un dataset mÃ¡s grande y con validaciÃ³n cruzada k-fold para confirmar los hallazgos.

---

## ğŸ“ Archivos Relevantes

| Archivo                                   | DescripciÃ³n                                    |
| ----------------------------------------- | ---------------------------------------------- |
| `outputs/resultados_gridsearch.csv`       | Mejores resultados por modelo                  |
| `outputs/todas_las_instancias.csv`        | MSE de cada combinaciÃ³n evaluada               |
| `outputs/grafico_mejores_modelos.png`     | GrÃ¡fico de barras con los mejores modelos      |
| `outputs/grafico_completo_parametros.png` | Curvas de MSE por configuraciÃ³n de cada modelo |

---

## ğŸ“Š 5. ComparaciÃ³n Visual de Coeficientes

Se presentan los coeficientes aprendidos por los tres modelos de regularizaciÃ³n: **Ridge**, **Lasso** y **ElasticNet**. Cada grÃ¡fico muestra el impacto relativo de cada variable sobre la predicciÃ³n del peso de los peces (`Weight`).

---

### ğŸ§± Ridge

![Coeficientes Ridge](outputs/coeficientes_ridge.png)

- `Length2`, `Length3` y `Length1` presentan los coeficientes mÃ¡s altos en magnitud.
- Las variables categÃ³ricas (`Species_*`) tienen una menor influencia, aunque no fueron eliminadas.
- Ridge tiende a **mantener todos los coeficientes** al aplicar penalizaciÃ³n L2, reduciendo su magnitud pero sin llevarlos a cero.

---

### âœ‚ï¸ Lasso

![Coeficientes Lasso](outputs/coeficientes_lasso.png)

- Se observa que algunas variables tienen coeficiente **exactamente cero**, lo que implica que fueron **eliminadas automÃ¡ticamente** del modelo.
- Variables eliminadas: `Height`, `Species_Whitefish`, `Species_Pike`, entre otras con coeficiente â‰ˆ 0.
- Lasso utiliza penalizaciÃ³n L1, lo que favorece la **selecciÃ³n automÃ¡tica de caracterÃ­sticas** y un modelo mÃ¡s interpretable.

---

### ğŸ”— ElasticNet

![Coeficientes ElasticNet](outputs/coeficientes_elasticnet.png)

- Ofrece un equilibrio entre Ridge y Lasso: **reduce** la magnitud de los coeficientes y elimina algunos.
- Las variables `Length1`, `Length2`, y `Length3` siguen siendo dominantes.
- Ãštil en presencia de **multicolinealidad**, ya que puede seleccionar grupos de variables correlacionadas.

---

## ğŸ§  6. DiscusiÃ³n Final

### âœ… Â¿CuÃ¡l fue mÃ¡s efectiva?

SegÃºn el grÃ¡fico de mejores MSE:

![Mejor MSE](outputs/grafico_mejores_modelos.png)

- **Ridge** fue el modelo mÃ¡s efectivo:
  - **Mejor MSE = 7033.27** con `alpha = 0.001`.
  - RegularizaciÃ³n suave que mantiene todas las variables.

---

### âŒ Â¿QuÃ© eliminÃ³ el modelo Lasso?

Lasso eliminÃ³ automÃ¡ticamente (coeficientes = 0):

- `Height`
- `Species_Whitefish`
- `Species_Pike`

Estas variables no aportaban significativamente a la predicciÃ³n y fueron descartadas.

---

### âš–ï¸ Â¿CÃ³mo impactÃ³ la regularizaciÃ³n?

| TÃ©cnica       | SelecciÃ³n de variables | Complejidad del modelo | Interpretabilidad |
|---------------|------------------------|------------------------|-------------------|
| **Ridge**     | âŒ No elimina variables | ğŸ”µ Completo             | ğŸŸ¡ Media          |
| **Lasso**     | âœ… Elimina variables    | ğŸŸ¢ Simple               | ğŸŸ¢ Alta           |
| **ElasticNet**| âš ï¸ Parcial              | ğŸ”µ Intermedio           | ğŸŸ¡ Buena          |

---

### ğŸ“ˆ ComparaciÃ³n de todas las configuraciones evaluadas

La siguiente visualizaciÃ³n muestra el desempeÃ±o (MSE) de cada configuraciÃ³n por tÃ©cnica de regularizaciÃ³n:

![ComparaciÃ³n completa](outputs/grafico_completo_parametros.png)

---

## ğŸ“Œ ConclusiÃ³n

- **Ridge** obtuvo el mejor desempeÃ±o general.
- **Lasso** ayudÃ³ a simplificar el modelo sin comprometer demasiado la precisiÃ³n.
- **ElasticNet** entregÃ³ un balance ideal para problemas con multicolinealidad entre predictores.

Cada tÃ©cnica ofrece ventajas distintas segÃºn el objetivo: rendimiento, simplicidad o interpretabilidad.



## ğŸ§¾ Resumen Ejecutivo

Este anÃ¡lisis muestra cÃ³mo las tÃ©cnicas de regularizaciÃ³n pueden afectar tanto el rendimiento como la interpretaciÃ³n de un modelo de regresiÃ³n lineal. Se aplicaron tres enfoques distintos con mÃºltiples configuraciones. Los resultados muestran que Ridge tuvo un mejor ajuste en este dataset, mientras que Lasso es Ãºtil para seleccionar variables mÃ¡s relevantes.

---




