# ğŸ§ª ClasificaciÃ³n de Diabetes con OptimizaciÃ³n de HiperparÃ¡metros

Este proyecto tiene como objetivo aplicar distintas tÃ©cnicas de optimizaciÃ³n de hiperparÃ¡metros a un modelo de clasificaciÃ³n de diabetes utilizando Random Forest. Se comparan las siguientes tÃ©cnicas:

- Entrenamiento base sin optimizaciÃ³n.
- Grid Search
- Random Search
- Optuna

## ğŸ“¦ InstalaciÃ³n

Puedes ejecutar el proyecto con `pip` (sin necesidad de instalar `conda`):

```bash
conda env create --file environment.yml
conda activate especialidadmachinelearning
````


```bash
pip install pandas numpy matplotlib seaborn scikit-learn optuna
```

## â–¶ï¸ EjecuciÃ³n

Desde el directorio raÃ­z del proyecto, puedes correr el pipeline completo desde consola con:

```bash
python -m scripts.main
```

O bien, puedes generar y ejecutar el notebook automÃ¡ticamente:

```bash
python -m scripts.crear_notebook
```

Esto generarÃ¡ un archivo `notebooks/clasificacion_diabetes.ipynb` con todo el flujo visual.

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
Modulo4Clase1MarcoParra/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py               # Preprocesamiento y entrenamiento base
â”‚   â”œâ”€â”€ optimizacion.py        # GridSearch, RandomSearch, Optuna
â”‚   â”œâ”€â”€ visualizador.py        # Funciones de visualizaciÃ³n
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ main.py                # Script principal
â”‚   â”œâ”€â”€ crear_notebook.py      # Generador automÃ¡tico de notebook
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ clasificacion_diabetes.ipynb
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ comparacion_metricas_modelos.png
â”‚   â”œâ”€â”€ roc_base.png
â”‚   â”œâ”€â”€ matriz_confusion_base.png
â”‚   â””â”€â”€ ...
```

---

## ğŸ“Š AnÃ¡lisis de Resultados

Se evaluaron las mÃ©tricas F1-Score, PrecisiÃ³n, Recall y AUC para cada tÃ©cnica de entrenamiento.

### ğŸ“ˆ ComparaciÃ³n de mÃ©tricas por modelo

![ComparaciÃ³n de MÃ©tricas](outputs/comparacion_metricas_modelos.png)

> Podemos observar que los valores son similares, aunque Optuna logra una mejora leve en Recall respecto al modelo base.

---

### ğŸ“Œ Matrices de ConfusiÃ³n

| MÃ©todo       | Matriz de ConfusiÃ³n                                  |
| ------------ | ---------------------------------------------------- |
| Base         | ![Base](outputs/matriz_confusion_base.png)           |
| GridSearch   | ![Grid](outputs/matriz_confusion_gridsearch.png)     |
| RandomSearch | ![Random](outputs/matriz_confusion_randomsearch.png) |
| Optuna       | ![Optuna](outputs/matriz_confusion_optuna.png)       |

---

### ğŸ“Œ Curvas ROC

| MÃ©todo       | Curva ROC                               |
| ------------ | --------------------------------------- |
| Base         | ![Base](outputs/roc_base.png)           |
| GridSearch   | ![Grid](outputs/roc_gridsearch.png)     |
| RandomSearch | ![Random](outputs/roc_randomsearch.png) |
| Optuna       | ![Optuna](outputs/roc_optuna.png)       |

> El AUC permanece estable (\~0.82) en todos los mÃ©todos, demostrando buena capacidad de discriminaciÃ³n.

---

## ğŸš€ TecnologÃ­as Utilizadas

* Python 3.8
* Scikit-learn
* Optuna
* Matplotlib
* Seaborn
* Pandas / Numpy

---

## ğŸ“Œ ConclusiÃ³n

Aunque los mÃ©todos de optimizaciÃ³n no generan diferencias drÃ¡sticas en el rendimiento, permiten explorar automÃ¡ticamente el espacio de hiperparÃ¡metros y detectar combinaciones Ã³ptimas. Optuna, en particular, destaca por su eficiencia y facilidad de integraciÃ³n.

---

