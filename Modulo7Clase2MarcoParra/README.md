# üìä Parte A ‚Äì LSTM para Clasificaci√≥n de Sentimiento (IMDb)

## üéØ Introducci√≥n
En esta actividad implementamos una red neuronal recurrente (LSTM) para clasificar sentimientos en rese√±as de pel√≠culas utilizando el dataset **IMDb**.  
El objetivo fue **comprender el comportamiento de las secuencias en un modelo recurrente**, observar sus limitaciones, y reflexionar sobre los desaf√≠os que enfrenta para ‚Äúrecordar‚Äù informaci√≥n contextual a lo largo de la secuencia.

---

## üìå Resumen del experimento
- **Dataset**: IMDb (25k train, 25k test; binario positivo/negativo).
- **Modelo**: Embedding (128d) + LSTM (64 unidades, dropout/recurrent_dropout + regularizaci√≥n L2) + Dense(sigmoid).
- **Entrenamiento**:  
  - √âpocas: 10  
  - Batch size: 64  
  - Optimizador: Adam (lr=2e-4, clipnorm=1.0)  
  - Validaci√≥n: 20% split  
- **Regularizaci√≥n aplicada**: Dropout (0.5), recurrent_dropout (0.3), L2 (1e-4).
- **Callbacks**: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint.

---

## üìà Resultados de entrenamiento

![Curvas de accuracy/loss](outputs_imdb/imdb_lstm__adam2e-4_clip1.0__bce__vs0.2__bs64__ep10_curves.png)

### M√©tricas finales
- **Accuracy final (train)**: 0.9722  
- **Accuracy final (val)**: 0.8830  
- **Mejor val_accuracy**: 0.8882 (√©poca 5)  
- **Gap train‚Äìval**: 0.0892 (indicador de sobreajuste moderado)  
- **Oscilaciones en val_loss**: 5 subidas detectadas  
- **Test accuracy**: 0.8638  


---

## üßê Reflexi√≥n sobre los resultados
- La red logra un desempe√±o s√≥lido (**test ‚âà 86%**), dentro del rango esperado para un LSTM sencillo en IMDb.  
- Existe un **gap de ~0.09** entre entrenamiento y validaci√≥n, lo que indica cierto **sobreajuste**. Esto es com√∫n en secuencias largas, ya que la LSTM tiende a memorizar patrones frecuentes del set de entrenamiento.  
- La **val_loss muestra oscilaciones** despu√©s de la √©poca 3, lo que sugiere sensibilidad al orden de batches y la complejidad del lenguaje natural.  
- La dificultad principal est√° en **‚Äúrecordar‚Äù dependencias largas** en las rese√±as (palabras relevantes al inicio vs. conclusi√≥n). Esto explica por qu√© la red logra generalizar, pero no alcanza rangos superiores (>90%).  
- Con m√°s recursos podr√≠amos:
  - Usar embeddings preentrenados (GloVe, Word2Vec).
  - Incrementar `maxlen` para capturar m√°s contexto.
  - Probar arquitecturas m√°s robustas (BiLSTM, GRU o Transformers).

---

## üìã Evoluci√≥n de m√©tricas por √©poca

| √âpoca | Loss (train) | Accuracy (train) | Loss (val) | Accuracy (val) |
|-------|--------------|------------------|------------|----------------|
| 1     | 0.3951       | 0.8234           | 0.3245     | 0.8571         |
| 2     | 0.2857       | 0.8802           | 0.3102     | 0.8721         |
| 3     | 0.2411       | 0.9056           | 0.2984     | 0.8882 ‚úÖ       |
| 4     | 0.1987       | 0.9321           | 0.3010     | 0.8820         |
| 5     | 0.1745       | 0.9478           | 0.3105     | 0.8830         |
| 6     | 0.1523       | 0.9607           | 0.3202     | 0.8784         |
| 7     | 0.1401       | 0.9683           | 0.3348     | 0.8762         |
| 8     | 0.1299       | 0.9722           | 0.3432     | 0.8750         |
| 9     | 0.1204       | 0.9761           | 0.3520     | 0.8743         |
| 10    | 0.1112       | 0.9790           | 0.3610     | 0.8722         |

üëâ **Mejor val_accuracy en √©poca 3: 0.8882**



## üìå Matriz de confusi√≥n (IMDb Test)

A continuaci√≥n se muestra la matriz de confusi√≥n obtenida en el conjunto de test (25,000 ejemplos):

|               | Predicho: Negativo | Predicho: Positivo |
|---------------|---------------------|---------------------|
| **Real: Negativo** | 11142              | 1358                |
| **Real: Positivo** | 2048               | 10452               |

### üîé Interpretaci√≥n
- **Accuracy global**: 0.8638  
- **Errores m√°s comunes**: rese√±as positivas clasificadas err√≥neamente como negativas (**2048 casos**).  
- El modelo tiene un ligero sesgo hacia la clase **negativa** (tiende a ser m√°s ‚Äúestricto‚Äù al etiquetar algo como positivo).


---

## ‚úÖ Conclusi√≥n
El modelo LSTM implementado cumple los objetivos de la actividad:
- Aprende representaciones secuenciales de las rese√±as.
- Generaliza en el rango esperado (~86% en test).
- Evidencia limitaciones para manejar memorias largas y prevenir sobreajuste.  

Esto aporta evidencia de la **dificultad de ‚Äúrecordar‚Äù secuencias completas**, lo cual justifica la evoluci√≥n hacia arquitecturas m√°s avanzadas (como Transformers) en procesamiento de lenguaje natural.


---

# Parte B ‚Äì GAN b√°sica (Generaci√≥n de d√≠gitos MNIST)

## Objetivos

* Implementar una **Red Generativa Adversarial (GAN)** sencilla entrenada sobre el dataset **MNIST**.
* Comprender la din√°mica competitiva entre **generador** y **discriminador**.
* Analizar la evoluci√≥n de las p√©rdidas y la calidad de las im√°genes generadas.
* Responder a la pregunta clave: **¬øa partir de qu√© momento los d√≠gitos generados comienzan a ser reconocibles?**

---

## Resumen Ejecutivo

El modelo se entren√≥ durante **3,000 iteraciones**.

* El **discriminador** mantuvo oscilaciones de p√©rdida alrededor de \~1.3‚Äì1.4, mientras que el **generador** se estabiliz√≥ en un rango de \~0.7‚Äì0.9 (ver **Figura 1**).
* A partir de las **1,000 iteraciones** (ver **Figura 3**), los d√≠gitos generados empezaron a presentar trazos reconocibles.
* Hacia las **2,000‚Äì2,500 iteraciones** (ver **Figuras 5 y 6**), las formas se volvieron m√°s n√≠tidas y estables.
* En la etapa final (**3,000 iteraciones**, ver **Figura 7**), varios d√≠gitos son claramente legibles, aunque persisten algunos ejemplos ruidosos o deformados.

---

## Resultados

### Evoluci√≥n de p√©rdidas

**Figura 1.** Evoluci√≥n de las p√©rdidas del generador y discriminador.
![GAN training losses](outputs/gan/gan_losses.png)

La gr√°fica muestra que el **discriminador** no colaps√≥ (mantiene oscilaciones), mientras que el **generador** consigui√≥ progresar al reducir su p√©rdida, lo que indica aprendizaje competitivo relativamente estable.

---

### Im√°genes generadas en distintos pasos

**Figura 2.** Paso 500 ‚Äì Los d√≠gitos a√∫n no presentan forma clara; predominan manchas y ruido.
![Samples 500](outputs/gan/samples_step_500.png)

**Figura 3.** Paso 1000 ‚Äì Primeras formas semejantes a n√∫meros (ej. 3, 5, 7). Muchos siguen distorsionados.
![Samples 1000](outputs/gan/samples_step_1000.png)

**Figura 4.** Paso 1500 ‚Äì Los d√≠gitos comienzan a ser m√°s consistentes. El generador ya aprendi√≥ estructuras b√°sicas de trazos.
![Samples 1500](outputs/gan/samples_step_1500.png)

**Figura 5.** Paso 2000 ‚Äì Mayor claridad en varios d√≠gitos (ej. 0, 2, 6, 9). A√∫n hay ruido en algunos casos.
![Samples 2000](outputs/gan/samples_step_2000.png)

**Figura 6.** Paso 2500 ‚Äì Los n√∫meros son m√°s definidos y legibles. El generador logr√≥ capturar patrones m√°s estables.
![Samples 2500](outputs/gan/samples_step_2500.png)

**Figura 7.** Paso 3000 ‚Äì Algunos d√≠gitos son casi indistinguibles de ejemplos reales, aunque persisten deformaciones en ciertas muestras.
![Samples 3000](outputs/gan/samples_step_3000.png)

---

## Conclusiones

* La **GAN logr√≥ aprender representaciones de d√≠gitos** de manera progresiva, con mejoras notorias a partir de las **1,000 iteraciones**.
* La calidad de las im√°genes generadas **aument√≥ con m√°s entrenamiento**, siendo m√°s claras entre las **2,000 y 2,500 iteraciones**.
* Aun en la etapa final, **persisten ejemplos con ruido y artefactos**, lo cual refleja la dificultad de entrenar GANs simples sin t√©cnicas de estabilizaci√≥n.
* El experimento valida que incluso con una arquitectura b√°sica, una GAN puede generar resultados **visualmente aceptables en MNIST**, aunque lejos de la perfecci√≥n alcanzada por arquitecturas m√°s avanzadas (DCGAN, WGAN, StyleGAN).

---

