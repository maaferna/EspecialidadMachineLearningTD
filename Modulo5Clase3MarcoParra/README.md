# üß† Comparaci√≥n de M√©todos de Boosting y Bagging en Predicci√≥n de Ingresos

Este proyecto tiene como objetivo aplicar y comparar t√©cnicas de **ensamblaje supervisado** como **XGBoost**, **AdaBoost** (boosting), y **Random Forest** (bagging), sobre el conjunto de datos real **Adult Income**. La tarea consiste en predecir si una persona gana m√°s de $50K USD anuales en base a informaci√≥n demogr√°fica.

---

## üìÅ Estructura del Proyecto

```

‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # Script principal que ejecuta todo el pipeline
‚îÇ   ‚îî‚îÄ‚îÄ build\_notebook.py     # Script para generar notebook interactivo autom√°ticamente
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ utils.py              # Carga y preprocesamiento del dataset
‚îÇ   ‚îú‚îÄ‚îÄ modelos.py            # Entrenamiento de XGBoost, AdaBoost, RandomForest
‚îÇ   ‚îú‚îÄ‚îÄ evaluador.py          # M√©tricas de evaluaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ visualizador.py       # Visualizaci√≥n de resultados (matriz de confusi√≥n, comparativas)
‚îÇ
‚îú‚îÄ‚îÄ outputs/                  # Carpeta con CSVs, im√°genes y m√©tricas exportadas
‚îÇ
‚îú‚îÄ‚îÄ environment.yml           # Ambiente Conda reproducible
‚îú‚îÄ‚îÄ requirements.txt          # Alternativa con pip
‚îî‚îÄ‚îÄ README.md                 # Este archivo

````

---

## üöÄ Ejecuci√≥n del Proyecto

1. **Crear ambiente virtual (opcional):**

```bash
conda env create -f environment.yml
conda activate especialidad-machine-learning
````

2. **Ejecutar script principal:**

```bash
python -m scripts.main
```

---

## üìä An√°lisis del Dataset y Preprocesamiento

### üîπ Dataset: [Adult Income](https://archive.ics.uci.edu/ml/datasets/adult)

* **Origen**: UCI Machine Learning Repository
* **Tama√±o original**: 32.561 filas, 15 columnas
* **Tarea**: Clasificaci√≥n binaria (`income` > 50K USD)

### üßπ Preprocesamiento Realizado

| Proceso                   | Detalles                                       |
| ------------------------- | ---------------------------------------------- |
| Carga del dataset         | Utiliza `fetch_openml` con versi√≥n est√°ndar    |
| Filtrado de valores nulos | Eliminadas 4.262 filas con valores `?`         |
| Binarizaci√≥n del target   | `>50K` ‚Üí 1, `<=50K` ‚Üí 0                        |
| Detecci√≥n de columnas     | 8 categ√≥ricas, 6 num√©ricas                     |
| One-Hot Encoding          | 8 columnas categ√≥ricas ‚Üí 98 columnas dummy     |
| Escalamiento              | Aplicado `StandardScaler` a columnas num√©ricas |
| Divisi√≥n train/test       | 80% entrenamiento, 20% test                    |

### üì¶ Dataset final

```text
‚úÖ Dataset limpio con 32.561 filas y 15 columnas.
üßπ Filas con nulos eliminadas: 4.262
üéØ Target: income ‚Üí binarizado
üîç Columnas categ√≥ricas: 8 ‚Üí one-hot encoded (98 columnas)
üîç Columnas num√©ricas: 6 ‚Üí escaladas
üìä Total columnas finales: 104

‚úÖ X_train: (24.129, 104)
‚úÖ X_test : (6.033, 104)
```

---

## üß™ Modelos a Comparar

| Tipo     | Algoritmo     |
| -------- | ------------- |
| Boosting | XGBoost       |
| Boosting | AdaBoost      |
| Bagging  | Random Forest |

### üîß M√©tricas de Evaluaci√≥n

* Accuracy
* Matriz de Confusi√≥n
* Curva ROC / AUC (opcional)
* Visualizaciones comparativas

---

## üìà Visualizaciones y Resultados

üìÇ Todos los resultados se almacenan en la carpeta `outputs/`:

| Tipo de salida         | Archivo generado          |
| ---------------------- | ------------------------- |
| Resultados m√©tricas    | `*.csv` por cada modelo   |
| Matriz de confusi√≥n    | `confusion_matrix_*.png`  |
| Comparaci√≥n de modelos | `comparativa_modelos.png` |

---

## üìå Conclusiones (pendiente)

* Se completar√° tras entrenar los modelos.
* Se incluir√°n recomendaciones y elecci√≥n de modelo m√°s robusto.

---

## üìö Requisitos

* Python 3.8+
* Scikit-learn
* Pandas / NumPy
* Matplotlib / Seaborn
* XGBoost / LightGBM / CatBoost (opcionales)

---



## üìä An√°lisis de Resultados

### üß† Resumen Ejecutivo

En este an√°lisis se compararon cinco modelos de clasificaci√≥n aplicados al conjunto de datos **Adult Income**, con el objetivo de predecir si una persona gana m√°s de 50K anuales en funci√≥n de variables demogr√°ficas.
Se aplicaron t√©cnicas de *Boosting* y *Bagging*, evaluando su rendimiento principalmente con m√©tricas de **accuracy** y **matriz de confusi√≥n**.

Los modelos evaluados fueron:

* Random Forest (Bagging)
* AdaBoost (Boosting)
* XGBoost (Boosting)
* LightGBM (Boosting)
* CatBoost (Boosting)

Cada modelo fue ajustado usando **GridSearchCV** y sus mejores resultados fueron almacenados y visualizados.

---

### üìà Comparaci√≥n de Accuracy entre los Mejores Modelos

La siguiente figura muestra el accuracy alcanzado por el **mejor conjunto de hiperpar√°metros** para cada modelo:

![Comparaci√≥n de Accuracy](outputs/comparacion_accuracy.png)

> ‚úÖ **Interpretaci√≥n**: El gr√°fico permite comparar directamente qu√© modelo fue m√°s preciso. El modelo con mayor barra present√≥ el mejor desempe√±o global.

---

### üì¶ Distribuci√≥n de Accuracy por Todas las Configuraciones

Este gr√°fico muestra la variabilidad del rendimiento (accuracy) para **todas las combinaciones de hiperpar√°metros** evaluadas en cada modelo:

![Distribuci√≥n Accuracy Todos los Modelos](outputs/accuracy_todos_modelos.png)

> üîç **An√°lisis**: Este gr√°fico es √∫til para ver la **robustez del modelo**. Modelos con distribuciones m√°s compactas y altos valores medianos son m√°s confiables.

---

### üîç Matrices de Confusi√≥n de los Mejores Modelos

Estas matrices permiten evaluar los errores tipo I y tipo II para cada modelo seleccionado como "mejor":

#### üî∏ CatBoost

![Matriz CatBoost](outputs/confusion_matrix_catboost.png)

#### üî∏ XGBoost

![Matriz XGBoost](outputs/confusion_matrix_xgboost.png)

#### üî∏ Random Forest

![Matriz RandomForest](outputs/confusion_matrix_randomforest.png)

#### üî∏ AdaBoost

![Matriz AdaBoost](outputs/confusion_matrix_adaboost.png)

#### üî∏ LightGBM

![Matriz LightGBM](outputs/confusion_matrix_lightgbm.png)

> üßÆ **Interpretaci√≥n**: Las diagonales indican las clasificaciones correctas. Los errores (falsos positivos y negativos) se muestran fuera de la diagonal.

---

### üìå Conclusiones

* El modelo **CatBoost** obtuvo el mejor desempe√±o en t√©rminos de *accuracy*.
* **XGBoost** y **LightGBM** tambi√©n ofrecieron rendimientos muy competitivos, con distribuciones de accuracy estables.
* **AdaBoost** y **RandomForest** presentaron resultados aceptables, aunque con menor precisi√≥n.
* La evaluaci√≥n exhaustiva mediante m√∫ltiples combinaciones de hiperpar√°metros ayud√≥ a identificar los mejores modelos.
* En t√©rminos de interpretaci√≥n y rendimiento, **CatBoost** ser√≠a recomendado para producci√≥n en este caso.

---



## ‚úçÔ∏è Autor

Marco Antonio Fern√°ndez Parra
Especializaci√≥n en Machine Learning ‚Äî Talento Digital Chile

---


