from nbformat import v4 as nbf
from pathlib import Path

# Crear celdas para el notebook
cells = []

# Celda 1: instalaci√≥n de dependencias
cells.append(nbf.new_code_cell(
    """\
# Requisitos para ejecutar este notebook
!pip install matplotlib seaborn scikit-learn pandas
"""
))

# Celda 2: configuraci√≥n inline de gr√°ficos
cells.append(nbf.new_code_cell(
    """\
# Configuraci√≥n para mostrar gr√°ficos en el notebook
%matplotlib inline
"""
))

# Celda 3: importaciones
cells.append(nbf.new_code_cell(
    """\
from sklearn.exceptions import UndefinedMetricWarning
from src.utils import cargar_dataset, preprocesar_datos
import warnings
from src.modelos import (
    crear_modelo_random_forest,
    crear_modelo_logistic_regression,
    crear_modelo_svc,
)
from src.validacion import (
    obtener_kfold,
    obtener_loocv,
    obtener_stratified_kfold,
)
from src.evaluador import evaluar_metricas
from src.visualizador import (
    graficar_metricas_individuales,
    plot_metricas_comparativas
)

# Suprimir advertencias de m√©tricas indefinidas
warnings.filterwarnings("ignore", category=UndefinedMetricWarning)
"""
))

# Celda 4: carga y preprocesamiento
cells.append(nbf.new_code_cell(
    """\
# ================================
# Carga y preprocesamiento
# ================================
df = cargar_dataset()
X, y, _ = preprocesar_datos(df)
"""
))

# Celda 5: definici√≥n de modelos
cells.append(nbf.new_code_cell(
    """\
# ================================
# Modelos
# ================================
modelos = {
    "RandomForest": crear_modelo_random_forest(),
    "LogisticRegression": crear_modelo_logistic_regression(),
    # "SVC": crear_modelo_svc()
}
"""
))

# Celda 6: definici√≥n de validadores
cells.append(nbf.new_code_cell(
    """\
# ================================
# T√©cnicas de Validaci√≥n Cruzada
# ================================
validaciones = {
    "KFold": obtener_kfold(n_splits=5),
    # "LeaveOneOut": obtener_loocv(X.values, y.values, n_samples=1000)[0],
    "StratifiedKFold": obtener_stratified_kfold(n_splits=5, random_state=42)
}
"""
))

# Celda 7: evaluaci√≥n + gr√°ficas individuales
cells.append(nbf.new_code_cell(
    """\
# ================================
# Evaluaci√≥n + Gr√°ficas Individuales
# ================================
resultados = []

for nombre_modelo, modelo in modelos.items():
    for nombre_validacion, validador in validaciones.items():
        print(f"\\nüîç Evaluando {nombre_modelo} con {nombre_validacion}...")

        # Evaluaci√≥n m√©trica
        metricas = evaluar_metricas(modelo, X.values, y.values, validador)
        metricas["modelo"] = nombre_modelo
        metricas["estrategia"] = nombre_validacion
        resultados.append(metricas)

        # Dividir manualmente para visualizar graficas (solo primera partici√≥n)
        train_idx, test_idx = next(iter(validador.split(X, y)))
        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]
        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]

        # Gr√°ficas individuales
        graficar_metricas_individuales(
            modelo, X_train, y_train, X_test, y_test,
            nombre_modelo=nombre_modelo, nombre_validacion=nombre_validacion
        )
"""
))

# Celda 8: visualizaci√≥n final
cells.append(nbf.new_code_cell(
    """\
# ================================
# Visualizaci√≥n Comparativa Final
# ================================
plot_metricas_comparativas(resultados)

print("\\n‚úÖ Evaluaci√≥n y visualizaci√≥n completadas.")
"""
))

# Crear el notebook
notebook = nbf.new_notebook(cells=cells)
notebook_path = Path("notebook/main_pipeline.ipynb")
notebook_path.write_text(nbf.writes(notebook))

notebook_path.name
