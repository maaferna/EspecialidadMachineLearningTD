# ðŸ§  Proyecto: ComparaciÃ³n de TÃ©cnicas Avanzadas para PredicciÃ³n de Ingresos

Este proyecto aplica y compara modelos avanzados de **regresiÃ³n y clasificaciÃ³n** sobre el dataset **Adult Income**, con foco en precisiÃ³n, estabilidad e interpretabilidad.

## ðŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ data/                # Dataset 'adult' descargado desde OpenML
â”œâ”€â”€ notebooks/           # Noteb#!/bin/bash

# Crear entorno Conda
echo "ðŸ“¦ Creando entorno conda 'especialidadmachinelearning'..."
conda env create -f environment.yml

# Activar entorno (solo aplica en terminal interactiva)
echo "âš ï¸  Para activar el entorno, ejecuta manualmente:"
echo "   conda activate especialidadmachinelearning"

# Crear carpetas necesarias
echo "ðŸ“ Creando estructura de carpetas..."
mkdir -p data outputs scripts src


echo "âœ… Estructura lista. Ejecuta:"
echo "   conda activate especialidadmachinelearning"
echo "   python scripts/main.py"
ook generado al final
â”œâ”€â”€ outputs/             # ImÃ¡genes, grÃ¡ficas, mÃ©tricas
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ main.py              # Script principal para entrenamiento y evaluaciÃ³n
â”‚   â””â”€â”€ crear_notebook.py    # Script para generar el notebook automÃ¡ticamente
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py             # Funciones de carga y preprocesamiento
â”‚   â”œâ”€â”€ modelos.py           # ImplementaciÃ³n de ElasticNet, RF, XGBoost, etc.
â”‚   â”œâ”€â”€ evaluador.py         # MÃ©tricas para regresiÃ³n y clasificaciÃ³n
â”‚   â””â”€â”€ visualizador.py      # VisualizaciÃ³n: curvas ROC, matrices, comparativas
â”œâ”€â”€ environment.yml          # Entorno conda para reproducibilidad
â””â”€â”€ README.md
```

## âš™ï¸ Modelos Involucrados

- **Elastic Net**
- **RegresiÃ³n CuantÃ­lica** (percentiles 10, 50, 90)
- **Random Forest**
- **XGBoost**

## ðŸ” EvaluaciÃ³n

- ClasificaciÃ³n: accuracy, matriz de confusiÃ³n, curva ROC
- RegresiÃ³n: RMSE, Pinball Loss

## ðŸš€ Instrucciones

1. Crear el entorno:

```bash
conda env create -f environment.yml
conda activate especialidadmachinelearning
```

2. Ejecutar el pipeline:

```bash
python -m scripts.main
```

3. Generar el notebook:

```bash
python -m scripts.crear_notebook
```

## ðŸ“Œ Notas

- Dataset utilizado: `fetch_openml("adult", version=2)`
- Para regresiÃ³n cuantÃ­lica: usar `QuantileRegressor` de `scikit-learn >=1.1`
- Pipeline modular, orientado a producciÃ³n y anÃ¡lisis crÃ­tico

---


### ðŸŽ¯ Enfoque Adoptado: RegresiÃ³n vs ClasificaciÃ³n

El enunciado plantea:

> **â€œAplicar y comparar modelos avanzados de regresiÃ³n y clasificaciÃ³n sobre un mismo problema.â€**

A partir de esto, se identifican dos enfoques distintos sobre el mismo dataset (`adult` de OpenML):

* **ClasificaciÃ³n binaria**: Predecir si una persona gana `>50K` o `<=50K` al aÃ±o.
* **RegresiÃ³n**: Predecir una **representaciÃ³n continua** o un **percentil estimado** del ingreso (e.g. mediante ElasticNet o RegresiÃ³n CuantÃ­lica).

#### âœ… Modelos Aplicados

Se utilizaron los siguientes modelos segÃºn su naturaleza:

| Modelo               | Tipo de Problema | ImplementaciÃ³n                                    |
| -------------------- | ---------------- | ------------------------------------------------- |
| Elastic Net          | RegresiÃ³n        | `ElasticNet` de `sklearn.linear_model`            |
| RegresiÃ³n CuantÃ­lica | RegresiÃ³n        | `QuantileRegressor` con percentiles 0.1, 0.5, 0.9 |
| Random Forest        | ClasificaciÃ³n    | `RandomForestClassifier`                          |
| XGBoost              | ClasificaciÃ³n    | `XGBClassifier`                                   |

#### â— Nota Importante

No se aplicaron los modelos de clasificaciÃ³n (Random Forest, XGBoost) a tareas de regresiÃ³n, ni viceversa, ya que:

* No se indica explÃ­citamente en el enunciado que cada modelo deba ser evaluado en ambos enfoques.
* Cada modelo fue utilizado conforme a su mejor desempeÃ±o habitual y su tipo de salida esperada.

---


# ðŸ“Š AnÃ¡lisis Detallado de Resultados

## 1. ClasificaciÃ³n: Random Forest y XGBoost

### Rendimiento General

Los modelos de clasificaciÃ³n evaluados fueron **Random Forest** y **XGBoost**. Ambos muestran un desempeÃ±o muy competitivo, con **XGBoost ligeramente superior**:

- **XGBoost** obtuvo una precisiÃ³n (`accuracy`) de **0.8669**.
- **Random Forest** logrÃ³ **0.8569**.

ðŸ“Œ **VisualizaciÃ³n**: grÃ¡fico de barras comparativo:  
![ComparaciÃ³n ClasificaciÃ³n y RegresiÃ³n](outputs/comparacion_metricas_modelos.png)

---

### Curvas ROC y AUC

- **XGBoost** AUC = **0.93**  
![Curva ROC XGBoost](outputs/roc_xgboost.png)

- **Random Forest** AUC = **0.91**  
![Curva ROC RandomForest](outputs/roc_randomforest.png)

---

### Matrices de ConfusiÃ³n

- **XGBoost**  
  - Verdaderos negativos: 6375  
  - Verdaderos positivos: 1466  
  - Falsos negativos: 776  
![Matriz XGBoost](outputs/matriz_confusion_xgboost.png)

- **Random Forest**  
  - Verdaderos negativos: 6434  
  - Verdaderos positivos: 1317  
  - Falsos negativos: 925  
![Matriz RandomForest](outputs/matriz_confusion_randomforest.png)

---

## 2. RegresiÃ³n: ElasticNet vs Quantile Regression

### ComparaciÃ³n de MÃ©tricas

- **ElasticNet** (RMSE): **0.3426**
- **QuantileRegressor** valores de Pinball Loss:
  - QuantileRegressor-0.1: **0.024**
  - QuantileRegressor-0.3: **0.073**
  - QuantileRegressor-0.6: **0.145**

ðŸ“Œ VisualizaciÃ³n de mÃ©tricas por modelo de regresiÃ³n:  
![ComparaciÃ³n RegresiÃ³n](outputs/comparacion_regresion_mejores.png)

ðŸ“Œ Comparativa general:  
![Comparativa General](outputs/comparacion_metricas_modelos.png)

---

### DispersiÃ³n Cuantil vs Alpha

La grÃ¡fica muestra cÃ³mo el **Pinball Loss** varÃ­a segÃºn el cuantil y `alpha`.  
El mejor rendimiento se observa para **Î± = 0.1** en casi todos los cuantiles.  
![DispersiÃ³n Cuantiles](outputs/dispersion_cuantiles.png)

---

## 3. VisualizaciÃ³n de PredicciÃ³n vs Real (ElasticNet)

Se observa que **ElasticNet no logra capturar bien los valores extremos (0 y 1)**, con predicciones concentradas en el centro del rango.

![PredicciÃ³n vs Real ElasticNet](outputs/pred_vs_real_elasticnet.png)

---

## âœ… Conclusiones Finales

- **XGBoost** es el mejor modelo de clasificaciÃ³n (precisiÃ³n y AUC).
- **ElasticNet** no es ideal para este problema de regresiÃ³n.
- **QuantileRegressor**, especialmente con `alpha=0.1`, mostrÃ³ los mejores resultados de predicciÃ³n en tÃ©rminos de Pinball Loss.



---

### ðŸ“Š AnÃ¡lisis de Resultados â€“ QuantileRegressor con Quantil 0.1

#### 1. **Objetivo del modelo con quantil 0.1**

El modelo `QuantileRegressor` entrenado con un **quantil de 0.1** busca estimar el percentil 10 de la distribuciÃ³n condicional de la variable objetivo. En otras palabras, predice un valor por debajo del cual se espera que se encuentren el 10% de los valores reales, dado un conjunto de variables independientes.

Este tipo de regresiÃ³n es especialmente Ãºtil para entender el **comportamiento de la cola inferior** de la distribuciÃ³n, lo cual puede ser valioso para estudios de **riesgo bajo o rendimiento mÃ­nimo**.

---

#### 2. **Resultados observados**

De acuerdo a los resultados entregados en consola:

```
[QuantileRegressor-0.1, Î±=0.1] Pinball Loss: 0.0244
[QuantileRegressor-0.1, Î±=0.5] Pinball Loss: 0.0244
[QuantileRegressor-0.1, Î±=1.0] Pinball Loss: 0.0244
```

* Se observa que el **Pinball Loss es muy bajo (â‰ˆ0.0244)** y **constante** para todas las combinaciones de `alpha` (0.1, 0.5, 1.0).
* Esto sugiere que **la regularizaciÃ³n no tiene un impacto significativo** en la predicciÃ³n del cuantil 0.1 en este dataset.
* El modelo ha logrado un excelente ajuste para este percentil, lo que se refleja en la grÃ¡fica de dispersiÃ³n, donde los valores predichos se agrupan correctamente en el rango esperado para la cola inferior.

---

#### 3. **ComparaciÃ³n con otros cuantiles**

Comparando el quantil 0.1 con otros como 0.5 (la mediana) o 0.9, observamos que:

* **El Pinball Loss es menor para el quantil 0.1**. Esto puede indicar que:

  * El modelo tiene mayor facilidad para predecir correctamente los valores bajos del target.
  * O bien, que la cola inferior del target es **mÃ¡s estable o menos dispersa**, y por ende mÃ¡s fÃ¡cil de ajustar.

* En contraste, para cuantiles mÃ¡s altos (por ejemplo 0.7 o 0.9), el error aumenta progresivamente, lo cual podrÃ­a estar relacionado con **mayor variabilidad en las colas superiores** de la distribuciÃ³n.

---

#### 4. **Implicaciones del resultado**

* **Ventaja operativa**: si el problema de negocio o investigaciÃ³n requiere una predicciÃ³n conservadora (por ejemplo, una predicciÃ³n mÃ­nima de ingresos, rendimiento o producciÃ³n), el quantil 0.1 serÃ­a una herramienta muy Ãºtil.
* **Robustez del modelo**: la consistencia en el Pinball Loss frente a cambios en `alpha` demuestra que el modelo estÃ¡ bien ajustado para este cuantil y **no depende fuertemente de la regularizaciÃ³n**.
* **ValidaciÃ³n visual**: las grÃ¡ficas de dispersiÃ³n confirman que la lÃ­nea de predicciÃ³n sigue correctamente la tendencia esperada para valores bajos del objetivo.

---

