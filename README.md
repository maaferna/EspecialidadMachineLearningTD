# ğŸ§  Especialidad Machine Learning â€” Talento Digital para Chile (Kibernum)

> Repositorio oficial de proyectos desarrollados durante la **EspecializaciÃ³n en Machine Learning**, impartida por **Talento Digital para Chile** a travÃ©s de la **OTEC Kibernum** (2024â€“2025).
> Contiene mÃºltiples mÃ³dulos y proyectos aplicados en Ã¡reas de **aprendizaje supervisado, no supervisado, NLP, MLOps, interpretabilidad y Ã©tica en IA**.

---

## ğŸ¯ Objetivo General

DiseÃ±ar, entrenar, explicar y desplegar modelos de Machine Learning en entornos controlados, aplicando **principios de ingenierÃ­a, Ã©tica y reproducibilidad**.
El repositorio reÃºne proyectos de distinto enfoque (supervisado, no supervisado y MLOps), cada uno con sus respectivos resultados, documentaciÃ³n y cÃ³digo ejecutable.

---

## ğŸ§© Estructura General del Repositorio

```bash
EspecialidadMachineLearningTD/
â”‚
â”œâ”€â”€ Modulo3EvalMod_MarcoParra/           # RegresiÃ³n lineal y optimizaciÃ³n (GD/SGD)
â”œâ”€â”€ Modulo5OptimizacionHiperparametros/  # RayTune, Optuna, Skopt, GridSearch, etc.
â”œâ”€â”€ Modulo7ScoringCrediticio/            # Modelos de riesgo crediticio (LogReg, RF)
â”œâ”€â”€ Modulo8RedesNeuronales/              # DNN y ResNet aplicadas a German Credit
â”œâ”€â”€ Modulo9ClusteringAnomalias/          # SegmentaciÃ³n no supervisada y anomalÃ­as
â”œâ”€â”€ Modulo10MLMLOpsDocker/               # API ML contenerizada con Flask + Docker
â”œâ”€â”€ NLP_NotasClinicas/                   # ClasificaciÃ³n de notas clÃ­nicas (TF-IDF, LIME, SHAP)
â”œâ”€â”€ Interpretabilidad_LIME_SHAP/         # Explicabilidad de modelos tabulares
â””â”€â”€ README.md                            # Este documento
```

Cada mÃ³dulo incluye su propio `README.md`, con instrucciones de instalaciÃ³n, ejecuciÃ³n, mÃ©tricas y visualizaciones.


---

# âš™ï¸ Tech Stack Consolidado â€” Especialidad Machine Learning

![Python](https://img.shields.io/badge/Python-3.8â€“3.11-blue?logo=python\&logoColor=white)
![Conda](https://img.shields.io/badge/Conda-Env-green?logo=anaconda)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange?logo=jupyter)
![NumPy](https://img.shields.io/badge/NumPy-1.26-lightblue?logo=numpy)
![Pandas](https://img.shields.io/badge/Pandas-Dataframe-purple?logo=pandas)
![Matplotlib](https://img.shields.io/badge/Matplotlib-Visualization-orange)
![Seaborn](https://img.shields.io/badge/Seaborn-Stats--Plots-teal)

---

## ğŸ¤– Machine Learning & Deep Learning

![Scikit-learn](https://img.shields.io/badge/scikit--learn-ML-orange?logo=scikitlearn)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow)
![XGBoost](https://img.shields.io/badge/XGBoost-GradientBoosting-red)
![Optuna](https://img.shields.io/badge/Optuna-Hyperparameter--Tuning-lightgrey)
![RayTune](https://img.shields.io/badge/RayTune-Distributed--Tuning-blueviolet)
![Hyperopt](https://img.shields.io/badge/Hyperopt-Optimization-green)
![Skopt](https://img.shields.io/badge/Skopt-Bayesian--Opt-gray)

---

## ğŸ’¬ Procesamiento de Lenguaje Natural (NLP)

![spaCy](https://img.shields.io/badge/spaCy-NLP-blue?logo=spacy)
![NLTK](https://img.shields.io/badge/NLTK-TextProcessing-green)
![TF-IDF](https://img.shields.io/badge/TF--IDF-Vectorization-lightblue)
![Word2Vec](https://img.shields.io/badge/Word2Vec-Embeddings-yellow)
![FastText](https://img.shields.io/badge/FastText-WordEmbeddings-orange)
![Transformers](https://img.shields.io/badge/Transformers-BERT%2FBETO%2FDistilUSE-violet?logo=huggingface)

---

## ğŸ” Interpretabilidad y Ã‰tica

![SHAP](https://img.shields.io/badge/SHAP-ExplainableAI-red)
![LIME](https://img.shields.io/badge/LIME-ModelInterpretability-green)
![Fairness](https://img.shields.io/badge/Fairness-Bias%20Audit-lightgrey)
![ExplainableAI](https://img.shields.io/badge/Explainable--AI-ResponsibleML-blue)

---

## ğŸ§© MLOps, APIs & ContenerizaciÃ³n

![Docker](https://img.shields.io/badge/Docker-Containerization-blue?logo=docker)
![Docker Compose](https://img.shields.io/badge/Docker--Compose-Orchestration-navy)
![Flask](https://img.shields.io/badge/Flask-API--Backend-black?logo=flask)
![Gunicorn](https://img.shields.io/badge/Gunicorn-WSGI-green)
![Micromamba](https://img.shields.io/badge/Micromamba-Lightweight--Conda-teal)
![Postman](https://img.shields.io/badge/Postman-API--Testing-orange?logo=postman)
![CI/CD](https://img.shields.io/badge/GitHub--Actions-CI%2FCD-lightgrey?logo=githubactions)

---

## ğŸŒ Web, Backend & Cloud

![Django](https://img.shields.io/badge/Django-4.x-green?logo=django)
![Bootstrap](https://img.shields.io/badge/Bootstrap-Frontend-purple?logo=bootstrap)
![Vue](https://img.shields.io/badge/Vue.js-UI--Components-brightgreen?logo=vuedotjs)
![React](https://img.shields.io/badge/React-Dashboard-blue?logo=react)
![Heroku](https://img.shields.io/badge/Heroku-Deployment-purple?logo=heroku)
![Google Drive](https://img.shields.io/badge/Google%20Drive-Cloud%20Integration-yellow?logo=googledrive)
![GitHub](https://img.shields.io/badge/GitHub-VersionControl-black?logo=github)
![Linux](https://img.shields.io/badge/Linux-Ubuntu--20.04--24.04-orange?logo=linux)

---

## ğŸ§  AnÃ¡lisis, VisualizaciÃ³n y Ciencia de Datos

![Pandas Profiling](https://img.shields.io/badge/Pandas--Profiling-EDA-blue)
![Seaborn](https://img.shields.io/badge/Seaborn-StatisticalPlots-cyan)
![Matplotlib](https://img.shields.io/badge/Matplotlib-Visualizations-orange)
![Plotly](https://img.shields.io/badge/Plotly-InteractiveGraphs-lightblue)
![UMAP](https://img.shields.io/badge/UMAP-Dimensionality--Reduction-teal)
![HDBSCAN](https://img.shields.io/badge/HDBSCAN-Clustering-green)
![IsolationForest](https://img.shields.io/badge/IsolationForest-Anomaly--Detection-gray)
![OneClassSVM](https://img.shields.io/badge/One--Class--SVM-Outlier--Detection-yellowgreen)

---

## ğŸ§° Dev Tools & Reproducibilidad

![VSCode](https://img.shields.io/badge/VSCode-Editor-blue?logo=visualstudiocode)
![Git](https://img.shields.io/badge/Git-VersionControl-orange?logo=git)
![pytest](https://img.shields.io/badge/pytest-UnitTesting-green?logo=pytest)
![YAML](https://img.shields.io/badge/YAML-Configs-lightgrey)
![Markdown](https://img.shields.io/badge/Markdown-Documentation-black)
![JSON](https://img.shields.io/badge/JSON-DataExchange-lightgreen)
![CSV](https://img.shields.io/badge/CSV-Datasets-yellow)
![VirtualEnv](https://img.shields.io/badge/VirtualEnv-ReproducibleEnvs-teal)


---



## ğŸ§  Principales Proyectos

### 1ï¸âƒ£ RegresiÃ³n Lineal y MÃ©todos de OptimizaciÃ³n

ğŸ“ `Modulo3EvalMod_MarcoParra/`

* **Objetivo:** comparar *Gradient Descent* y *Stochastic Gradient Descent* en un problema de regresiÃ³n lineal.
* **TecnologÃ­as:** Python, NumPy, Matplotlib, pytest.
* **Resultados:** ambos mÃ©todos convergen hacia la soluciÃ³n analÃ­tica con diferencias de estabilidad; se implementan tests automatizados y manejo de excepciones.
* **Output:** `Modulo3Clase4/outputs/comparacion_gd_sgd.png`
![M3Output](Modulo3EvalMod_MarcoParra/outputs/comparacion_gd_sgd.png)

---

### 2ï¸âƒ£ OptimizaciÃ³n de HiperparÃ¡metros

ğŸ“ `Modulo4ptimizacionHiperparametros/`


* **Objetivo:** evaluar diferentes tÃ©cnicas de *hyperparameter tuning* (GridSearch, RandomSearch, Optuna, RayTune, Skopt, Hyperopt).
* **Modelo base:** `RandomForestClassifier`.
* **ConclusiÃ³n:** la validaciÃ³n cruzada (CV) evita sobreajuste y refleja mejor el rendimiento real.
* **Resultados visuales:** curvas ROC, matrices de confusiÃ³n y comparativas de mÃ©tricas.
* **Output:** `Modulo5OptimizacionHiperparametros/outputs_cv/comparacion_metricas_modelos.png`

![Matriz Optuna](Modulo4EvalMarcoParrra/outputs/matriz_confusion_optuna.png)
![ROC GridSearch](Modulo4EvalMarcoParrra/outputs/roc_gridsearch.png)


### 7ï¸âƒ£ Sistema Inteligente de Scoring Crediticio con Redes Neuronales Profundas

ğŸ“ `Modulo7RedesNeuronales/`

* **Objetivo:** desarrollar un sistema de *scoring crediticio* que combine precisiÃ³n, explicabilidad y robustez mediante redes neuronales profundas (DNN y ResNet tabular) sobre el dataset **German Credit (UCI)**.
* **TecnologÃ­as:** Python 3.10 | TensorFlow 2.15 | scikit-learn | SHAP | LIME | Matplotlib | Seaborn.
* **Enfoque:** comparaciÃ³n de dos arquitecturas (DNN vs ResNet) bajo el mismo preprocesamiento y conjunto de hiperparÃ¡metros, incorporando anÃ¡lisis de costos (FN > FP) y evaluaciÃ³n de interpretabilidad.
* **Resultados principales:**
  - **Accuracy (test):** 0.76  |  **AUC:** 0.81  |  **F1-Score:** 0.44  
  - **Costo esperado:** â‰ˆ 191 unidades (penalizaciÃ³n FN Ã— 5).  
  - **Variables mÃ¡s influyentes (SHAP):** `credit_amount`, `duration_months`, `status_checking`, `credit_history`.

---

#### ğŸ“Š GrÃ¡ficos de Resultados

<p align="center">
  <img src="Modulo7EvalModularMarcoParra/outputs/curves.png" width="48%" alt="Curvas de entrenamiento (Loss/Accuracy)" />
  <img src="Modulo7EvalModularMarcoParra/outputs/roc.png" width="48%" alt="Curva ROC del modelo DNN" />
</p>

<p align="center">
  <img src="Modulo7EvalModularMarcoParra/outputs/shap.png" width="48%" alt="SHAP Summary - Importancia de Variables" />
  <img src="Modulo7EvalModularMarcoParra/outputs/matriz_conf.png" width="48%" alt="Matriz de ConfusiÃ³n - Resultados de Test" />
</p>



---

### 4ï¸âƒ£ Redes Neuronales Profundas para Scoring Crediticio

ğŸ“ `Modulo8RedesNeuronales/`

* **Objetivo:** comparar una **DNN** y una **ResNet tabular** para predecir impago en *German Credit (UCI)*.
* **TecnologÃ­as:** TensorFlow/Keras, scikit-learn, SHAP, LIME, Matplotlib.
* **Enfoque:** mismos preprocesos e hiperparÃ¡metros base; anÃ¡lisis de costos (FN > FP) y explicabilidad.
* **Outputs clave (grÃ¡ficos):**

<p align="center">
  <img src="Modulo8EvalModularMarcoParra/reports/figures/confusion_matrix_linear_svm_tfidf.png" width="49%" alt="ResNet - Curvas de entrenamiento (loss/accuracy)" />
  <img src="Modulo8EvalModularMarcoParra/reports/figures/confusion_matrix.png" width="49%" alt="ResNet - Curva ROC" />
</p>
/home/mparraf/myprojects/EspecialidadMachineLearning/
<p align="center">
  <img src="Modulo8EvalModularMarcoParra/reports/figures/explainability/lime_ex_4.png" width="49%" alt="DNN - SHAP summary (importancia de variables)" />
  <img src="Modulo8EvalModularMarcoParra/reports/figures/explainability/shap_ex_4.png" width="49%" alt="DNN - Matriz de confusiÃ³n (ejemplo de test)" />
</p>

> **CÃ³mo leerlos:**
> - *Curves:* pÃ©rdida cae y la accuracy de validaciÃ³n se estabiliza (indica aprendizaje sin sobreajuste severo).
> - *ROC:* capacidad de discriminaciÃ³n entre impago/no-impago (AUC alto = mejor).
> - *SHAP:* variables con mayor impacto en la predicciÃ³n (p. ej., `duration_months`, `credit_amount`).
> - *Matriz:* distribuciÃ³n de aciertos/errores; recuerda ponderar el costo de **FN** frente a **FP**.



---

### 5ï¸âƒ£ Scoring Crediticio con Interpretabilidad (Lasso/Ridge, SHAP & LIME)

ğŸ“ `Modulo5Clase6EvalModMarcoParra/`

* **Objetivo:** construir un modelo de *scoring crediticio* para predecir el riesgo de impago utilizando **tÃ©cnicas de regularizaciÃ³n** (L1/L2) y mÃ©todos de **interpretabilidad** como **SHAP** y **LIME**.  
* **Modelos:** Logistic Regression (Lasso/Ridge) Â· Random Forest.  
* **Dataset:** `credit` (OpenML)  
* **EvaluaciÃ³n:** Accuracy, F1, AUC, Matriz de confusiÃ³n y Curva ROC.

---

#### ğŸ“Š ComparaciÃ³n de Modelos

| Modelo              | Accuracy | F1-Score | AUC  |
|----------------------|----------|----------|------|
| **Random Forest**    | 0.779    | 0.775    | 0.858 |
| **Logistic Regression** | 0.729 | 0.700    | 0.794 |

ğŸ“ *Random Forest ofrece mejor capacidad predictiva; Logistic Regression aporta interpretabilidad y transparencia regulatoria.*

---

#### ğŸ“ˆ Visualizaciones de Resultados

<p align="center">
  <img src="Modulo5Clase6EvalModMarcoParra/outputs/feature_importance_randomforest.png" width="48%" alt="Importancia de variables - RandomForest" />
  <img src="Modulo5Clase6EvalModMarcoParra/outputs/roc_curve_randomforest.png" width="48%" alt="Curva ROC - RandomForest" />
</p>

<p align="center">
  <img src="Modulo5Clase6EvalModMarcoParra/outputs/coeficientes_logisticregression.png" width="48%" alt="Coeficientes - Logistic Regression" />
  <img src="Modulo5Clase6EvalModMarcoParra/outputs/roc_curve_logisticregression.png" width="48%" alt="Curva ROC - Logistic Regression" />
</p>

> **InterpretaciÃ³n breve:**  
> - **Random Forest:** logra mayor AUC y mejor equilibrio entre precisiÃ³n y recall.  
> - **Logistic Regression:** permite interpretar directamente el impacto de cada variable.  
> - **SHAP/LIME:** refuerzan la trazabilidad y explicabilidad de las decisiones.

---

#### ğŸ’¬ ConclusiÃ³n
La combinaciÃ³n de **Random Forest + SHAP/LIME** entrega un modelo potente y explicable para scoring crediticio, ideal para uso en sistemas financieros donde se requiere **precisiÃ³n y transparencia**.

---

### 9ï¸âƒ£ Interpretabilidad de Modelos Predictivos (LIME & SHAP)

ğŸ“ `Modulo9Interpretabilidad_LIME_SHAP/`

* **Objetivo:** ilustrar la explicabilidad de un modelo **Random Forest** aplicado al dataset *Heart Failure Prediction (Kaggle)*, utilizando **SHAP** y **LIME** para entender quÃ© variables determinan las predicciones.
* **Modelo base:** Random Forest Classifier (Accuracy â‰ˆ 0.91, F1 â‰ˆ 0.92).
* **Variables mÃ¡s influyentes:** `ST_Slope`, `ChestPainType`, `Cholesterol`.

---

#### ğŸ“Š Ejemplos de Interpretabilidad

<p align="center">
  <img src="Modulo9EvalModularMarcoParra/images/shap_summary_beeswarm.png" width="48%" alt="SHAP â€“ Impacto global de variables" />
  <img src="Modulo9EvalModularMarcoParra/images/shap_waterfall_case_1.png" width="48%" alt="SHAP â€“ ExplicaciÃ³n local de un caso" />
</p>

<p align="center">
  <img src="Modulo9EvalModularMarcoParra/images/lime_explanation_case_1.png" width="48%" alt="LIME â€“ Caso 1" />
  <img src="Modulo9EvalModularMarcoParra/images/lime_explanation_case_2.png" width="48%" alt="LIME â€“ Caso 2" />
</p>

> **InterpretaciÃ³n breve:**  
> - **SHAP** muestra el efecto promedio de cada variable y cÃ³mo influye en casos individuales.  
> - **LIME** explica localmente quÃ© caracterÃ­sticas impulsan o reducen la probabilidad de la clase positiva.  
> - Ambos mÃ©todos permiten **auditar decisiones** y **detectar posibles sesgos** asociados a variables sensibles.

---

ğŸ“ˆ *El mÃ³dulo demuestra cÃ³mo integrar explicabilidad y Ã©tica en modelos de Machine Learning aplicados a salud, reforzando transparencia y trazabilidad.*

---

### 6ï¸âƒ£ SegmentaciÃ³n y DetecciÃ³n de AnomalÃ­as en Pacientes CrÃ³nicos

ğŸ“ `Modulo6EvalModularMarcoParra/`

* **Objetivo:** aplicar tÃ©cnicas **no supervisadas** (clustering y detecciÃ³n de anomalÃ­as) para identificar **patrones clÃ­nicos** y **pacientes atÃ­picos** en un dataset de enfermedades crÃ³nicas (diabetes, hipertensiÃ³n, obesidad).
* **TÃ©cnicas principales:** PCA Â· UMAP Â· DBSCAN Â· HDBSCAN Â· Isolation Forest Â· One-Class SVM.  
* **Dataset:** *Diabetes (Kaggle)* Â· 639 registros post-filtrado Â· 8 variables clÃ­nicas numÃ©ricas.

---

#### ğŸ“Š Visualizaciones de Resultados

<p align="center">
  <img src="Modulo6EvalModularMarcoParra/outputs/viz_PCA_2D_-_Clustering_Basado_en_Densidad.png" width="48%" alt="PCA 2D - Clustering Basado en Densidad" />
  <img src="Modulo6EvalModularMarcoParra/outputs/viz_UMAP_Visualization.png" width="48%" alt="UMAP - VisualizaciÃ³n No Lineal" />
</p>

<p align="center">
  <img src="Modulo6EvalModularMarcoParra/outputs/cm_IsolationForest_contamination0.05_gamma0.1_nu0.05.png" width="48%" alt="Matriz de ConfusiÃ³n - Isolation Forest" />
  <img src="Modulo6EvalModularMarcoParra/outputs/cm_OneClassSVM_contamination0.05_gamma0.1_nu0.05.png" width="48%" alt="Matriz de ConfusiÃ³n - One-Class SVM" />
</p>

> **InterpretaciÃ³n:**  
> - **PCA/UMAP:** permiten observar agrupamientos naturales y posibles subpoblaciones.  
> - **Isolation Forest:** detecta los casos mÃ¡s extremos, con menos falsos positivos.  
> - **One-Class SVM:** identifica mÃ¡s anomalÃ­as, pero con menor especificidad.  
> - La combinaciÃ³n de **HDBSCAN + Isolation Forest** ofrece un equilibrio entre sensibilidad e interpretabilidad clÃ­nica.

---

#### ğŸ’¬ ConclusiÃ³n breve
El mÃ³dulo demuestra cÃ³mo combinar **reducciÃ³n de dimensionalidad**, **clustering basado en densidad** y **detecciÃ³n de anomalÃ­as** para descubrir perfiles atÃ­picos de pacientes.  
La metodologÃ­a es aplicable en contextos de salud para apoyar la **detecciÃ³n temprana de riesgos** y la **interpretaciÃ³n visual de patrones clÃ­nicos**.


---

### 8ï¸âƒ£ API de Machine Learning Contenerizada (MLOps)

ğŸ“ `Modulo10MLMLOpsDocker/`

* **Objetivo:** construir una API REST reproducible para predicciones con modelo entrenado (*Breast Cancer Dataset*).
* **Stack:** Docker, Docker Compose, Flask, Gunicorn, Micromamba, Postman.
* **Servicios:**

  * `trainer`: entrena modelo y guarda artefactos en volumen persistente.
  * `api`: sirve predicciones en `/predict`.
* **MÃ©tricas del modelo:** Accuracy = 0.947 | F1 = 0.958.
* **Pruebas:** endpoints validados con Postman (`GET /`, `POST /predict`).

---

## ğŸ§° TecnologÃ­as y LibrerÃ­as Recurrentes

| CategorÃ­a          | Herramientas                                          |
| ------------------ | ----------------------------------------------------- |
| Lenguaje principal | Python 3.8â€“3.11                                       |
| Frameworks ML      | scikit-learn, TensorFlow, XGBoost                     |
| NLP                | spaCy, NLTK, TF-IDF, Word2Vec, FastText, Transformers |
| Interpretabilidad  | SHAP, LIME                                            |
| OptimizaciÃ³n       | Optuna, RayTune, Hyperopt, Skopt                      |
| VisualizaciÃ³n      | Matplotlib, Seaborn                                   |
| ContenerizaciÃ³n    | Docker, Docker Compose, Micromamba                    |
| Ã‰tica y Fairness   | auditorÃ­a por grupo, SHAP fairness analysis           |

---

## ğŸ“Š Resultados Globales

| Ãrea                        | Proyecto              | MÃ©tricas Destacadas                        |
| --------------------------- | --------------------- | ------------------------------------------ |
| **RegresiÃ³n Lineal**        | GD vs SGD             | MSE bajo y convergencia estable            |
| **OptimizaciÃ³n**            | Hyperparameter tuning | F1 â‰ˆ 0.9 (sin CV) â†’ F1 â‰ˆ 0.8 (con CV)      |
| **CrÃ©dito (ML clÃ¡sico)**    | LogReg / RF           | AUC 0.86                                   |
| **CrÃ©dito (Deep Learning)** | DNN / ResNet          | AUC 0.81 / 0.74                            |
| **Clustering / AnomalÃ­as**  | PCA + HDBSCAN         | Silhouette -0.09, ROC-AUC â‰ˆ 0.64           |
| **NLP clÃ­nico**             | SVM + TF-IDF          | Accuracy > 0.80, fairness equilibrado      |
| **Interpretabilidad**       | SHAP / LIME           | Variables clave y sesgos Ã©ticos detectados |
| **MLOps**                   | API Flask Docker      | Accuracy 0.947, F1 0.958                   |

---




---

## ğŸ§¾ Autor y Portafolio Profesional

**Marco Antonio Parra FernÃ¡ndez **  
Especialista en Machine Learning â€“ Talento Digital para Chile / Kibernum  
ğŸ“ Chile ğŸ‡¨ğŸ‡±  

ğŸ”— [GitHub @maaferna](https://github.com/maaferna) Â· [LinkedIn](https://www.linkedin.com/in/maaferna)  
ğŸŒ **Portafolio Web:** [https://portfolio-mparraf.herokuapp.com/](https://portfolio-mparraf.herokuapp.com/)

> Este portafolio integra los principales proyectos de la Especialidad Machine Learning, desplegados con **Django + Heroku**, con conexiÃ³n a repositorios GitHub y almacenamiento cloud.  
> Presenta mÃ³dulos de anÃ¡lisis, visualizaciÃ³n y modelos productivos, reflejando el enfoque aplicado y profesional de la especializaciÃ³n.

---

## ğŸ“œ Licencia

Este repositorio y sus mÃ³dulos estÃ¡n destinados a fines **acadÃ©micos, formativos y de portafolio profesional**.  
Licencia de uso: [MIT License](https://opensource.org/licenses/MIT)  
Â© 2025 â€” **Marco Antonio Parra FernÃ¡ndez**. Todos los derechos reservados.

---
