# 🧠 Especialidad Machine Learning — Talento Digital para Chile (Kibernum)

> Repositorio oficial de proyectos desarrollados durante la **Especialización en Machine Learning**, impartida por **Talento Digital para Chile** a través de la **OTEC Kibernum** (2024–2025).
> Contiene múltiples módulos y proyectos aplicados en áreas de **aprendizaje supervisado, no supervisado, NLP, MLOps, interpretabilidad y ética en IA**.

---

## 🎯 Objetivo General

Diseñar, entrenar, explicar y desplegar modelos de Machine Learning en entornos controlados, aplicando **principios de ingeniería, ética y reproducibilidad**.
El repositorio reúne proyectos de distinto enfoque (supervisado, no supervisado y MLOps), cada uno con sus respectivos resultados, documentación y código ejecutable.

---

## 🧩 Estructura General del Repositorio

```bash
EspecialidadMachineLearningTD/
│
├── Modulo3EvalMod_MarcoParra/           # Regresión lineal y optimización (GD/SGD)
├── Modulo5OptimizacionHiperparametros/  # RayTune, Optuna, Skopt, GridSearch, etc.
├── Modulo7ScoringCrediticio/            # Modelos de riesgo crediticio (LogReg, RF)
├── Modulo8RedesNeuronales/              # DNN y ResNet aplicadas a German Credit
├── Modulo9ClusteringAnomalias/          # Segmentación no supervisada y anomalías
├── Modulo10MLMLOpsDocker/               # API ML contenerizada con Flask + Docker
├── NLP_NotasClinicas/                   # Clasificación de notas clínicas (TF-IDF, LIME, SHAP)
├── Interpretabilidad_LIME_SHAP/         # Explicabilidad de modelos tabulares
└── README.md                            # Este documento
```

Cada módulo incluye su propio `README.md`, con instrucciones de instalación, ejecución, métricas y visualizaciones.


---

# ⚙️ Tech Stack Consolidado — Especialidad Machine Learning

![Python](https://img.shields.io/badge/Python-3.8–3.11-blue?logo=python\&logoColor=white)
![Conda](https://img.shields.io/badge/Conda-Env-green?logo=anaconda)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange?logo=jupyter)
![NumPy](https://img.shields.io/badge/NumPy-1.26-lightblue?logo=numpy)
![Pandas](https://img.shields.io/badge/Pandas-Dataframe-purple?logo=pandas)
![Matplotlib](https://img.shields.io/badge/Matplotlib-Visualization-orange)
![Seaborn](https://img.shields.io/badge/Seaborn-Stats--Plots-teal)

---

## 🤖 Machine Learning & Deep Learning

![Scikit-learn](https://img.shields.io/badge/scikit--learn-ML-orange?logo=scikitlearn)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow)
![XGBoost](https://img.shields.io/badge/XGBoost-GradientBoosting-red)
![Optuna](https://img.shields.io/badge/Optuna-Hyperparameter--Tuning-lightgrey)
![RayTune](https://img.shields.io/badge/RayTune-Distributed--Tuning-blueviolet)
![Hyperopt](https://img.shields.io/badge/Hyperopt-Optimization-green)
![Skopt](https://img.shields.io/badge/Skopt-Bayesian--Opt-gray)

---

## 💬 Procesamiento de Lenguaje Natural (NLP)

![spaCy](https://img.shields.io/badge/spaCy-NLP-blue?logo=spacy)
![NLTK](https://img.shields.io/badge/NLTK-TextProcessing-green)
![TF-IDF](https://img.shields.io/badge/TF--IDF-Vectorization-lightblue)
![Word2Vec](https://img.shields.io/badge/Word2Vec-Embeddings-yellow)
![FastText](https://img.shields.io/badge/FastText-WordEmbeddings-orange)
![Transformers](https://img.shields.io/badge/Transformers-BERT%2FBETO%2FDistilUSE-violet?logo=huggingface)

---

## 🔍 Interpretabilidad y Ética

![SHAP](https://img.shields.io/badge/SHAP-ExplainableAI-red)
![LIME](https://img.shields.io/badge/LIME-ModelInterpretability-green)
![Fairness](https://img.shields.io/badge/Fairness-Bias%20Audit-lightgrey)
![ExplainableAI](https://img.shields.io/badge/Explainable--AI-ResponsibleML-blue)

---

## 🧩 MLOps, APIs & Contenerización

![Docker](https://img.shields.io/badge/Docker-Containerization-blue?logo=docker)
![Docker Compose](https://img.shields.io/badge/Docker--Compose-Orchestration-navy)
![Flask](https://img.shields.io/badge/Flask-API--Backend-black?logo=flask)
![Gunicorn](https://img.shields.io/badge/Gunicorn-WSGI-green)
![Micromamba](https://img.shields.io/badge/Micromamba-Lightweight--Conda-teal)
![Postman](https://img.shields.io/badge/Postman-API--Testing-orange?logo=postman)
![CI/CD](https://img.shields.io/badge/GitHub--Actions-CI%2FCD-lightgrey?logo=githubactions)

---

## 🌐 Web, Backend & Cloud

![Django](https://img.shields.io/badge/Django-4.x-green?logo=django)
![Bootstrap](https://img.shields.io/badge/Bootstrap-Frontend-purple?logo=bootstrap)
![Vue](https://img.shields.io/badge/Vue.js-UI--Components-brightgreen?logo=vuedotjs)
![React](https://img.shields.io/badge/React-Dashboard-blue?logo=react)
![Heroku](https://img.shields.io/badge/Heroku-Deployment-purple?logo=heroku)
![Google Drive](https://img.shields.io/badge/Google%20Drive-Cloud%20Integration-yellow?logo=googledrive)
![GitHub](https://img.shields.io/badge/GitHub-VersionControl-black?logo=github)
![Linux](https://img.shields.io/badge/Linux-Ubuntu--20.04--24.04-orange?logo=linux)

---

## 🧠 Análisis, Visualización y Ciencia de Datos

![Pandas Profiling](https://img.shields.io/badge/Pandas--Profiling-EDA-blue)
![Seaborn](https://img.shields.io/badge/Seaborn-StatisticalPlots-cyan)
![Matplotlib](https://img.shields.io/badge/Matplotlib-Visualizations-orange)
![Plotly](https://img.shields.io/badge/Plotly-InteractiveGraphs-lightblue)
![UMAP](https://img.shields.io/badge/UMAP-Dimensionality--Reduction-teal)
![HDBSCAN](https://img.shields.io/badge/HDBSCAN-Clustering-green)
![IsolationForest](https://img.shields.io/badge/IsolationForest-Anomaly--Detection-gray)
![OneClassSVM](https://img.shields.io/badge/One--Class--SVM-Outlier--Detection-yellowgreen)

---

## 🧰 Dev Tools & Reproducibilidad

![VSCode](https://img.shields.io/badge/VSCode-Editor-blue?logo=visualstudiocode)
![Git](https://img.shields.io/badge/Git-VersionControl-orange?logo=git)
![pytest](https://img.shields.io/badge/pytest-UnitTesting-green?logo=pytest)
![YAML](https://img.shields.io/badge/YAML-Configs-lightgrey)
![Markdown](https://img.shields.io/badge/Markdown-Documentation-black)
![JSON](https://img.shields.io/badge/JSON-DataExchange-lightgreen)
![CSV](https://img.shields.io/badge/CSV-Datasets-yellow)
![VirtualEnv](https://img.shields.io/badge/VirtualEnv-ReproducibleEnvs-teal)


---



## 🧠 Principales Proyectos

### 1️⃣ Regresión Lineal y Métodos de Optimización

📁 `Modulo3EvalMod_MarcoParra/`

* **Objetivo:** comparar *Gradient Descent* y *Stochastic Gradient Descent* en un problema de regresión lineal.
* **Tecnologías:** Python, NumPy, Matplotlib, pytest.
* **Resultados:** ambos métodos convergen hacia la solución analítica con diferencias de estabilidad; se implementan tests automatizados y manejo de excepciones.
* **Output:** `Modulo3Clase4/outputs/comparacion_gd_sgd.png`
![M3Output](Modulo3EvalMod_MarcoParra/outputs/comparacion_gd_sgd.png)

---

### 2️⃣ Optimización de Hiperparámetros

📁 `Modulo4ptimizacionHiperparametros/`


* **Objetivo:** evaluar diferentes técnicas de *hyperparameter tuning* (GridSearch, RandomSearch, Optuna, RayTune, Skopt, Hyperopt).
* **Modelo base:** `RandomForestClassifier`.
* **Conclusión:** la validación cruzada (CV) evita sobreajuste y refleja mejor el rendimiento real.
* **Resultados visuales:** curvas ROC, matrices de confusión y comparativas de métricas.
* **Output:** `Modulo5OptimizacionHiperparametros/outputs_cv/comparacion_metricas_modelos.png`

![Matriz Optuna](Modulo4EvalMarcoParrra/outputs/matriz_confusion_optuna.png)
![ROC GridSearch](Modulo4EvalMarcoParrra/outputs/roc_gridsearch.png)


### 7️⃣ Sistema Inteligente de Scoring Crediticio con Redes Neuronales Profundas

📁 `Modulo7RedesNeuronales/`

* **Objetivo:** desarrollar un sistema de *scoring crediticio* que combine precisión, explicabilidad y robustez mediante redes neuronales profundas (DNN y ResNet tabular) sobre el dataset **German Credit (UCI)**.
* **Tecnologías:** Python 3.10 | TensorFlow 2.15 | scikit-learn | SHAP | LIME | Matplotlib | Seaborn.
* **Enfoque:** comparación de dos arquitecturas (DNN vs ResNet) bajo el mismo preprocesamiento y conjunto de hiperparámetros, incorporando análisis de costos (FN > FP) y evaluación de interpretabilidad.
* **Resultados principales:**
  - **Accuracy (test):** 0.76  |  **AUC:** 0.81  |  **F1-Score:** 0.44  
  - **Costo esperado:** ≈ 191 unidades (penalización FN × 5).  
  - **Variables más influyentes (SHAP):** `credit_amount`, `duration_months`, `status_checking`, `credit_history`.

---

#### 📊 Gráficos de Resultados

<p align="center">
  <img src="Modulo7EvalModularMarcoParra/outputs/curves.png" width="48%" alt="Curvas de entrenamiento (Loss/Accuracy)" />
  <img src="Modulo7EvalModularMarcoParra/outputs/roc.png" width="48%" alt="Curva ROC del modelo DNN" />
</p>

<p align="center">
  <img src="Modulo7EvalModularMarcoParra/outputs/shap.png" width="48%" alt="SHAP Summary - Importancia de Variables" />
  <img src="Modulo7EvalModularMarcoParra/outputs/matriz_conf.png" width="48%" alt="Matriz de Confusión - Resultados de Test" />
</p>



---

### 4️⃣ Redes Neuronales Profundas para Scoring Crediticio

📁 `Modulo8RedesNeuronales/`

* **Objetivo:** comparar una **DNN** y una **ResNet tabular** para predecir impago en *German Credit (UCI)*.
* **Tecnologías:** TensorFlow/Keras, scikit-learn, SHAP, LIME, Matplotlib.
* **Enfoque:** mismos preprocesos e hiperparámetros base; análisis de costos (FN > FP) y explicabilidad.
* **Outputs clave (gráficos):**

<p align="center">
  <img src="Modulo8EvalModularMarcoParra/reports/figures/confusion_matrix_linear_svm_tfidf.png" width="49%" alt="ResNet - Curvas de entrenamiento (loss/accuracy)" />
  <img src="Modulo8EvalModularMarcoParra/reports/figures/confusion_matrix.png" width="49%" alt="ResNet - Curva ROC" />
</p>
/home/mparraf/myprojects/EspecialidadMachineLearning/
<p align="center">
  <img src="Modulo8EvalModularMarcoParra/reports/figures/explainability/lime_ex_4.png" width="49%" alt="DNN - SHAP summary (importancia de variables)" />
  <img src="Modulo8EvalModularMarcoParra/reports/figures/explainability/shap_ex_4.png" width="49%" alt="DNN - Matriz de confusión (ejemplo de test)" />
</p>

> **Cómo leerlos:**
> - *Curves:* pérdida cae y la accuracy de validación se estabiliza (indica aprendizaje sin sobreajuste severo).
> - *ROC:* capacidad de discriminación entre impago/no-impago (AUC alto = mejor).
> - *SHAP:* variables con mayor impacto en la predicción (p. ej., `duration_months`, `credit_amount`).
> - *Matriz:* distribución de aciertos/errores; recuerda ponderar el costo de **FN** frente a **FP**.



---

### 5️⃣ Scoring Crediticio con Interpretabilidad (Lasso/Ridge, SHAP & LIME)

📁 `Modulo5Clase6EvalModMarcoParra/`

* **Objetivo:** construir un modelo de *scoring crediticio* para predecir el riesgo de impago utilizando **técnicas de regularización** (L1/L2) y métodos de **interpretabilidad** como **SHAP** y **LIME**.  
* **Modelos:** Logistic Regression (Lasso/Ridge) · Random Forest.  
* **Dataset:** `credit` (OpenML)  
* **Evaluación:** Accuracy, F1, AUC, Matriz de confusión y Curva ROC.

---

#### 📊 Comparación de Modelos

| Modelo              | Accuracy | F1-Score | AUC  |
|----------------------|----------|----------|------|
| **Random Forest**    | 0.779    | 0.775    | 0.858 |
| **Logistic Regression** | 0.729 | 0.700    | 0.794 |

📎 *Random Forest ofrece mejor capacidad predictiva; Logistic Regression aporta interpretabilidad y transparencia regulatoria.*

---

#### 📈 Visualizaciones de Resultados

<p align="center">
  <img src="Modulo5Clase6EvalModMarcoParra/outputs/feature_importance_randomforest.png" width="48%" alt="Importancia de variables - RandomForest" />
  <img src="Modulo5Clase6EvalModMarcoParra/outputs/roc_curve_randomforest.png" width="48%" alt="Curva ROC - RandomForest" />
</p>

<p align="center">
  <img src="Modulo5Clase6EvalModMarcoParra/outputs/coeficientes_logisticregression.png" width="48%" alt="Coeficientes - Logistic Regression" />
  <img src="Modulo5Clase6EvalModMarcoParra/outputs/roc_curve_logisticregression.png" width="48%" alt="Curva ROC - Logistic Regression" />
</p>

> **Interpretación breve:**  
> - **Random Forest:** logra mayor AUC y mejor equilibrio entre precisión y recall.  
> - **Logistic Regression:** permite interpretar directamente el impacto de cada variable.  
> - **SHAP/LIME:** refuerzan la trazabilidad y explicabilidad de las decisiones.

---

#### 💬 Conclusión
La combinación de **Random Forest + SHAP/LIME** entrega un modelo potente y explicable para scoring crediticio, ideal para uso en sistemas financieros donde se requiere **precisión y transparencia**.

---

### 9️⃣ Interpretabilidad de Modelos Predictivos (LIME & SHAP)

📁 `Modulo9Interpretabilidad_LIME_SHAP/`

* **Objetivo:** ilustrar la explicabilidad de un modelo **Random Forest** aplicado al dataset *Heart Failure Prediction (Kaggle)*, utilizando **SHAP** y **LIME** para entender qué variables determinan las predicciones.
* **Modelo base:** Random Forest Classifier (Accuracy ≈ 0.91, F1 ≈ 0.92).
* **Variables más influyentes:** `ST_Slope`, `ChestPainType`, `Cholesterol`.

---

#### 📊 Ejemplos de Interpretabilidad

<p align="center">
  <img src="Modulo9EvalModularMarcoParra/images/shap_summary_beeswarm.png" width="48%" alt="SHAP – Impacto global de variables" />
  <img src="Modulo9EvalModularMarcoParra/images/shap_waterfall_case_1.png" width="48%" alt="SHAP – Explicación local de un caso" />
</p>

<p align="center">
  <img src="Modulo9EvalModularMarcoParra/images/lime_explanation_case_1.png" width="48%" alt="LIME – Caso 1" />
  <img src="Modulo9EvalModularMarcoParra/images/lime_explanation_case_2.png" width="48%" alt="LIME – Caso 2" />
</p>

> **Interpretación breve:**  
> - **SHAP** muestra el efecto promedio de cada variable y cómo influye en casos individuales.  
> - **LIME** explica localmente qué características impulsan o reducen la probabilidad de la clase positiva.  
> - Ambos métodos permiten **auditar decisiones** y **detectar posibles sesgos** asociados a variables sensibles.

---

📈 *El módulo demuestra cómo integrar explicabilidad y ética en modelos de Machine Learning aplicados a salud, reforzando transparencia y trazabilidad.*

---

### 6️⃣ Segmentación y Detección de Anomalías en Pacientes Crónicos

📁 `Modulo6EvalModularMarcoParra/`

* **Objetivo:** aplicar técnicas **no supervisadas** (clustering y detección de anomalías) para identificar **patrones clínicos** y **pacientes atípicos** en un dataset de enfermedades crónicas (diabetes, hipertensión, obesidad).
* **Técnicas principales:** PCA · UMAP · DBSCAN · HDBSCAN · Isolation Forest · One-Class SVM.  
* **Dataset:** *Diabetes (Kaggle)* · 639 registros post-filtrado · 8 variables clínicas numéricas.

---

#### 📊 Visualizaciones de Resultados

<p align="center">
  <img src="Modulo6EvalModularMarcoParra/outputs/viz_PCA_2D_-_Clustering_Basado_en_Densidad.png" width="48%" alt="PCA 2D - Clustering Basado en Densidad" />
  <img src="Modulo6EvalModularMarcoParra/outputs/viz_UMAP_Visualization.png" width="48%" alt="UMAP - Visualización No Lineal" />
</p>

<p align="center">
  <img src="Modulo6EvalModularMarcoParra/outputs/cm_IsolationForest_contamination0.05_gamma0.1_nu0.05.png" width="48%" alt="Matriz de Confusión - Isolation Forest" />
  <img src="Modulo6EvalModularMarcoParra/outputs/cm_OneClassSVM_contamination0.05_gamma0.1_nu0.05.png" width="48%" alt="Matriz de Confusión - One-Class SVM" />
</p>

> **Interpretación:**  
> - **PCA/UMAP:** permiten observar agrupamientos naturales y posibles subpoblaciones.  
> - **Isolation Forest:** detecta los casos más extremos, con menos falsos positivos.  
> - **One-Class SVM:** identifica más anomalías, pero con menor especificidad.  
> - La combinación de **HDBSCAN + Isolation Forest** ofrece un equilibrio entre sensibilidad e interpretabilidad clínica.

---

#### 💬 Conclusión breve
El módulo demuestra cómo combinar **reducción de dimensionalidad**, **clustering basado en densidad** y **detección de anomalías** para descubrir perfiles atípicos de pacientes.  
La metodología es aplicable en contextos de salud para apoyar la **detección temprana de riesgos** y la **interpretación visual de patrones clínicos**.


---

### 8️⃣ API de Machine Learning Contenerizada (MLOps)

📁 `Modulo10MLMLOpsDocker/`

* **Objetivo:** construir una API REST reproducible para predicciones con modelo entrenado (*Breast Cancer Dataset*).
* **Stack:** Docker, Docker Compose, Flask, Gunicorn, Micromamba, Postman.
* **Servicios:**

  * `trainer`: entrena modelo y guarda artefactos en volumen persistente.
  * `api`: sirve predicciones en `/predict`.
* **Métricas del modelo:** Accuracy = 0.947 | F1 = 0.958.
* **Pruebas:** endpoints validados con Postman (`GET /`, `POST /predict`).

---

## 🧰 Tecnologías y Librerías Recurrentes

| Categoría          | Herramientas                                          |
| ------------------ | ----------------------------------------------------- |
| Lenguaje principal | Python 3.8–3.11                                       |
| Frameworks ML      | scikit-learn, TensorFlow, XGBoost                     |
| NLP                | spaCy, NLTK, TF-IDF, Word2Vec, FastText, Transformers |
| Interpretabilidad  | SHAP, LIME                                            |
| Optimización       | Optuna, RayTune, Hyperopt, Skopt                      |
| Visualización      | Matplotlib, Seaborn                                   |
| Contenerización    | Docker, Docker Compose, Micromamba                    |
| Ética y Fairness   | auditoría por grupo, SHAP fairness analysis           |

---

## 📊 Resultados Globales

| Área                        | Proyecto              | Métricas Destacadas                        |
| --------------------------- | --------------------- | ------------------------------------------ |
| **Regresión Lineal**        | GD vs SGD             | MSE bajo y convergencia estable            |
| **Optimización**            | Hyperparameter tuning | F1 ≈ 0.9 (sin CV) → F1 ≈ 0.8 (con CV)      |
| **Crédito (ML clásico)**    | LogReg / RF           | AUC 0.86                                   |
| **Crédito (Deep Learning)** | DNN / ResNet          | AUC 0.81 / 0.74                            |
| **Clustering / Anomalías**  | PCA + HDBSCAN         | Silhouette -0.09, ROC-AUC ≈ 0.64           |
| **NLP clínico**             | SVM + TF-IDF          | Accuracy > 0.80, fairness equilibrado      |
| **Interpretabilidad**       | SHAP / LIME           | Variables clave y sesgos éticos detectados |
| **MLOps**                   | API Flask Docker      | Accuracy 0.947, F1 0.958                   |

---




---

## 🧾 Autor y Portafolio Profesional

**Marco Antonio Parra Fernández **  
Especialista en Machine Learning – Talento Digital para Chile / Kibernum  
📍 Chile 🇨🇱  

🔗 [GitHub @maaferna](https://github.com/maaferna) · [LinkedIn](https://www.linkedin.com/in/maaferna)  
🌐 **Portafolio Web:** [https://portfolio-mparraf.herokuapp.com/](https://portfolio-mparraf.herokuapp.com/)

> Este portafolio integra los principales proyectos de la Especialidad Machine Learning, desplegados con **Django + Heroku**, con conexión a repositorios GitHub y almacenamiento cloud.  
> Presenta módulos de análisis, visualización y modelos productivos, reflejando el enfoque aplicado y profesional de la especialización.

---

## 📜 Licencia

Este repositorio y sus módulos están destinados a fines **académicos, formativos y de portafolio profesional**.  
Licencia de uso: [MIT License](https://opensource.org/licenses/MIT)  
© 2025 — **Marco Antonio Parra Fernández**. Todos los derechos reservados.

---
