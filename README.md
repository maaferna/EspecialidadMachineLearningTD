# üìä Parte A ‚Äì LSTM para Clasificaci√≥n de Sentimiento (IMDb)

## üéØ Introducci√≥n
En esta actividad implementamos una red neuronal recurrente (LSTM) para clasificar sentimientos en rese√±as de pel√≠culas utilizando el dataset **IMDb**.  
El objetivo fue **comprender el comportamiento de las secuencias en un modelo recurrente**, observar sus limitaciones, y reflexionar sobre los desaf√≠os que enfrenta para ‚Äúrecordar‚Äù informaci√≥n contextual a lo largo de la secuencia.

---

## üìå Resumen del experimento
- **Dataset**: IMDb (25k train, 25k test; binario positivo/negativo).
- **Modelo**: Embedding (128d) + LSTM (64 unidades, dropout/recurrent_dropout + regularizaci√≥n L2) + Dense(sigmoid).
- **Entrenamiento**:  
  - √âpocas: 10  
  - Batch size: 64  
  - Optimizador: Adam (lr=2e-4, clipnorm=1.0)  
  - Validaci√≥n: 20% split  
- **Regularizaci√≥n aplicada**: Dropout (0.5), recurrent_dropout (0.3), L2 (1e-4).
- **Callbacks**: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint.

---

## üìà Resultados de entrenamiento

![Curvas de accuracy/loss](outputs_imdb/imdb_lstm__adam2e-4_clip1.0__bce__vs0.2__bs64__ep10_curves.png)

### M√©tricas finales
- **Accuracy final (train)**: 0.9722  
- **Accuracy final (val)**: 0.8830  
- **Mejor val_accuracy**: 0.8882 (√©poca 5)  
- **Gap train‚Äìval**: 0.0892 (indicador de sobreajuste moderado)  
- **Oscilaciones en val_loss**: 5 subidas detectadas  
- **Test accuracy**: 0.8638  

üìä **Matriz de confusi√≥n (test set)**  
![Confusion matrix](outputs_imdb/imdb_lstm__adam2e-4_clip1.0__bce__vs0.2__bs64__ep10_confusion_matrix.csv)

---

## üßê Reflexi√≥n sobre los resultados
- La red logra un desempe√±o s√≥lido (**test ‚âà 86%**), dentro del rango esperado para un LSTM sencillo en IMDb.  
- Existe un **gap de ~0.09** entre entrenamiento y validaci√≥n, lo que indica cierto **sobreajuste**. Esto es com√∫n en secuencias largas, ya que la LSTM tiende a memorizar patrones frecuentes del set de entrenamiento.  
- La **val_loss muestra oscilaciones** despu√©s de la √©poca 3, lo que sugiere sensibilidad al orden de batches y la complejidad del lenguaje natural.  
- La dificultad principal est√° en **‚Äúrecordar‚Äù dependencias largas** en las rese√±as (palabras relevantes al inicio vs. conclusi√≥n). Esto explica por qu√© la red logra generalizar, pero no alcanza rangos superiores (>90%).  
- Con m√°s recursos podr√≠amos:
  - Usar embeddings preentrenados (GloVe, Word2Vec).
  - Incrementar `maxlen` para capturar m√°s contexto.
  - Probar arquitecturas m√°s robustas (BiLSTM, GRU o Transformers).

---

## ‚úÖ Conclusi√≥n
El modelo LSTM implementado cumple los objetivos de la actividad:
- Aprende representaciones secuenciales de las rese√±as.
- Generaliza en el rango esperado (~86% en test).
- Evidencia limitaciones para manejar memorias largas y prevenir sobreajuste.  

Esto aporta evidencia de la **dificultad de ‚Äúrecordar‚Äù secuencias completas**, lo cual justifica la evoluci√≥n hacia arquitecturas m√°s avanzadas (como Transformers) en procesamiento de lenguaje natural.





---

## 4) Pruebas del endpoint

Puedes probar con **curl** o con el **script** incluido.

### Ejemplos con `curl`

```bash
# 1) OK ‚Äî setosa
curl -s -X POST http://127.0.0.1:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [5.1, 3.5, 1.4, 0.2]}' | jq

# 2) OK ‚Äî versicolor/virginica (ejemplo gen√©rico)
curl -s -X POST http://127.0.0.1:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [6.0, 2.9, 4.5, 1.5]}' | jq

# 3) Error ‚Äî longitud incorrecta
curl -s -X POST http://127.0.0.1:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [1, 2, 3]}' | jq
```

### `test_api.py`

```python

```

Ejecuta las pruebas (con la API ya corriendo):

```bash
python test_api.py
```

---

## 5) Manejo de errores

* **400 Bad Request**: entradas inv√°lidas (falta `features`, longitud incorrecta, tipos no num√©ricos, JSON malformado).
* **415 Unsupported Media Type**: `Content-Type` distinto de `application/json`.
* **500 Internal Server Error**: errores inesperados del servidor (trazados ocultos al cliente, mensaje claro).

---

## 6) Entrega (ZIP)

Para generar el zip con todo lo requerido (incluye `modelo.pkl` tras entrenar):

```bash
# Desde la carpeta que contiene flask_ml_api/
cd flask_ml_api
python train_model.py              # genera modelo.pkl
zip -r entrega_flask_ml_api.zip .  # app.py, modelo.pkl, train_model.py, test_api.py, environment.yml, README.md
```

---

## README de referencia

### `README.md`

````markdown
# API REST con Flask ‚Äî Clasificaci√≥n Iris

## Requisitos
- Conda/Miniconda

## Instalaci√≥n
```bash
conda env create -f environment.yml
conda activate flask-ml-api
````

## Entrenamiento

```bash
python train_model.py
# genera modelo.pkl
```

## Ejecutar API

```bash
python app.py
# http://127.0.0.1:5000/
```

## Probar

```bash
# OK\ ncurl -s -X POST http://127.0.0.1:5000/predict -H "Content-Type: application/json" -d '{"features":[5.1,3.5,1.4,0.2]}'

# Error (longitud)
curl -s -X POST http://127.0.0.1:5000/predict -H "Content-Type: application/json" -d '{"features":[1,2,3]}'
```

## Estructura

```
app.py
modelo.pkl
train_model.py
test_api.py
environment.yml
README.md
```

## Notas

* Modelo: RandomForestClassifier (sklearn) entrenado sobre Iris.
* Validaci√≥n: `features` debe ser lista num√©rica de 4 entradas.
* Respuesta: `{ "prediction": <clase> }` y, si disponible, `probabilities`.

```
```

---

## Extras opcionales

* **Gunicorn** para despliegues productivos (`pip install gunicorn`) y correr `gunicorn -w 2 -b 0.0.0.0:5000 app:app`.
* **Dockerfile** si deseas contenerizar (no requerido por esta actividad).

