
# üß† Sistema Inteligente de Scoring Crediticio con Redes Neuronales Profundas

## üìå Objetivo
Dise√±ar, entrenar y evaluar un modelo de red neuronal profunda para predecir la probabilidad de **impago de clientes bancarios**, utilizando el dataset *German Credit Data*. El modelo debe ser explicable, eficiente y presentar resultados interpretables en contextos financieros.

---

## üß™ Resumen Ejecutivo

Este proyecto compara dos arquitecturas de redes neuronales:
- ‚úÖ Una red **DNN profunda** con BatchNorm, Dropout y regularizaci√≥n L2.
- ‚úÖ Una red **ResNet ligera** para tabulares, con bloques residuales y skip connections.

Ambas arquitecturas se entrenan y eval√∫an bajo el mismo preprocesamiento, hiperpar√°metros y conjunto de datos. Adem√°s, se aplican t√©cnicas de interpretabilidad como **SHAP** y **LIME**.

---

## üìö Dataset

- **Fuente:** [UCI German Credit Data](https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data)
- **Target:** `class` (1 = "good credit", 2 = "bad credit")

---

## ‚öôÔ∏è Tecnolog√≠as y Librer√≠as

- Python 3.10
- TensorFlow 2.15.0 (compatible con GPU)
- scikit-learn
- pandas, numpy, matplotlib, seaborn
- SHAP (`shap`)
- LIME (`lime`)
- tqdm, argparse

---

## üì¶ Estructura del proyecto

```
.
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ credit_main.py             # Script principal de entrenamiento
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Modelos DNN y ResNet
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Carga, EDA, preprocesamiento
‚îÇ   ‚îú‚îÄ‚îÄ evaluator/                 # Entrenamiento y evaluaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ visualizer/               # Gr√°ficos (curvas, ROC, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ explain/                  # SHAP y LIME
‚îú‚îÄ‚îÄ outputs_credit/               # Resultados y artefactos
‚îî‚îÄ‚îÄ requirements.txt
```

---

## ‚öôÔ∏è Requisitos

Instalar dependencias desde `requirements.txt`:

```bash
pip install -r requirements.txt
```

---

## üöÄ Ejecuci√≥n

```bash
python scripts/credit_main.py --model both --mixed --epochs 50
```

Opciones disponibles:
- `--model`: `"dnn"`, `"resnet"` o `"both"`
- `--data`: ruta a CSV local o `"uci"` para descargar
- `--mixed`: activa precision mixta (si tu GPU lo permite)
- `--cost-fp` y `--cost-fn`: ponderaci√≥n del an√°lisis de costos

---



# üß† Sistema Inteligente de Scoring Crediticio con Redes Neuronales Profundas

## üéØ Objetivo del Proyecto

Desarrollar un sistema moderno de scoring crediticio que combine precisi√≥n, explicabilidad y robustez mediante modelos de redes neuronales profundas, utilizando el dataset German Credit (UCI). El sistema debe permitir interpretar las decisiones, analizar errores cr√≠ticos (tipo I y II) y ser aplicable a contextos financieros reales.

---

## üóÇÔ∏è Resumen Ejecutivo

- Se entren√≥ y evalu√≥ una red neuronal profunda (DNN) sobre 1.000 registros con 20 variables (13 categ√≥ricas y 7 num√©ricas).
- El modelo alcanz√≥ una **precisi√≥n del 76%**, con **AUC de 0.81** y un **costo esperado de 191 unidades** al ponderar falsos negativos 5 veces m√°s que los falsos positivos.
- Se analizaron los errores tipo I (FP = 11) y tipo II (FN = 36) desde una perspectiva financiera.
- Se utilizaron herramientas de explicabilidad (SHAP y LIME) para evaluar la importancia y el impacto de cada variable en las predicciones.
- El modelo demostr√≥ capacidad de generalizaci√≥n con bajo sobreajuste, validado por early stopping y m√©tricas robustas.
- Este enfoque es √∫til como base para sistemas de riesgo bancario con trazabilidad y transparencia.

---

## üß™ An√°lisis de Resultados ‚Äì Modelo DNN

## üî¢ Configuraci√≥n

- Arquitectura DNN: **7 capas densas** con 128 neuronas cada una
  - Esto se construy√≥ con: `stem_units=128`, `blocks=3`, `block_units=128`
  - Equivalente en estructura a la ResNet tabular (paridad).
- Regularizaci√≥n: Dropout 0.2 + L2 (`1e-5`)
- Normalizaci√≥n: BatchNormalization tras cada capa densa.
- Activaciones: ReLU despu√©s de cada BatchNorm.
- Optimizaci√≥n: `Adam` con `learning_rate=0.001`
- Tama√±o de batch: `256`
- Entrenamiento: `max_epochs=50`, EarlyStopping con paciencia=5

> ‚ö†Ô∏è Esta configuraci√≥n permite comparar justamente el desempe√±o de ambas arquitecturas (DNN vs ResNet), controlando por profundidad y complejidad param√©trica.


### üìä Curvas de entrenamiento

![Curvas de entrenamiento](outputs_credit/dnn__lr0.001__bs256__ep50_curves.png)

- La p√©rdida de validaci√≥n se estabiliz√≥ tempranamente.
- No se observ√≥ sobreajuste severo.
- La precisi√≥n de validaci√≥n se mantuvo cercana al 70%.

---

### üìâ M√©tricas finales

- **Accuracy test**: `0.76`
- **AUC test**: `0.81`
- **F1-score**: `0.44`
- **Recall (sensitivity)**: `0.40`
- **Precision**: `0.69`

```json
{
  "accuracy": 0.76,
  "roc_auc": 0.8129,
  "f1": 0.44,
  "recall": 0.40,
  "precision": 0.69,
  "confusion_matrix": [[129, 11], [36, 24]]
}
```

> üìå El modelo predice con alta precisi√≥n las clases positivas (sin impago), pero tiene margen de mejora en detecci√≥n de impagos reales.

---

### üßÆ An√°lisis de Costos

El costo esperado fue calculado como:

* `cost_fp = 1` (otorgar cr√©dito a quien no deber√≠a)
* `cost_fn = 5` (rechazar a alguien que pagar√≠a)

```json
{
  "TN": 129,
  "FP": 11,
  "FN": 36,
  "TP": 24,
  "cost_fp": 1.0,
  "cost_fn": 5.0,
  "expected_cost": 191.0
}
```

> ‚ö†Ô∏è El alto n√∫mero de falsos negativos representa el mayor componente del costo esperado. Este trade-off puede ajustarse modificando el threshold de decisi√≥n.

---

### üß† Matriz de Confusi√≥n

![Matriz de confusi√≥n](outputs_credit/dnn__lr0.001__bs256__ep50_cm.png)

* Tipo I (FP): 11 ‚Üí riesgo financiero moderado
* Tipo II (FN): 36 ‚Üí impacto significativo (se pierden buenos clientes)

---

### üìà Curva ROC

![Curva ROC](outputs_credit/dnn__lr0.001__bs256__ep50_roc.png)

> El √°rea bajo la curva (AUC ‚âà 0.81) indica buena capacidad de discriminaci√≥n entre impagos y no-impagos.

---

### üßÆ Importancia de Variables (SHAP)

![SHAP Summary](outputs_credit/dnn__lr0.001__bs256__ep50_shap_summary.png)

> Se observ√≥ alta importancia en variables como `credit_amount`, `duration_months`, `status_checking`, y `credit_history`. Estas influyen directamente en la probabilidad de default predicha por el modelo.

---

## üîç EDA Resumen

* Instancias totales: **1.000**
* Variables: **20**

  * Num√©ricas: `7` ‚Äî e.g., `credit_amount`, `age`, `duration_months`
  * Categ√≥ricas: `13` ‚Äî e.g., `status_checking`, `purpose`, `job`
* Clases:

  * `good` (700) = 70%
  * `bad` (300) = 30% ‚áí **dataset desbalanceado**

---

## ‚úÖ Pr√≥ximos pasos

* Comparar contra modelo ResNet.
* Ajustar umbral de clasificaci√≥n con base en m√©tricas de negocio.
* Aplicar calibraci√≥n de probabilidades (e.g., Platt scaling).
* Mejorar recall en clase de impago (FN).


---

## üìä Resultados: ResNet Tabular

### üß† Modelo
La arquitectura implementada corresponde a una variante ligera de **ResNet adaptada a datos tabulares**, con las siguientes caracter√≠sticas:

- `stem_units`: 128  
- `blocks`: 3  
- `block_units`: 128  
- Regularizaci√≥n L2: `1e-5`, Dropout: `0.2`  
- Total de capas internas: 7 (comparable a DNN)

### ‚úÖ Desempe√±o en Test
Basado en el archivo [`resnet__lr0.001__bs256__ep50_test_report.json`](./resnet__lr0.001__bs256__ep50_test_report.json), el modelo logr√≥:

| M√©trica        | Valor   |
|----------------|---------|
| Accuracy       | 0.72    |
| F1-Score       | 0.60    |
| AUC-ROC        | 0.74    |
| Precisi√≥n (1)  | 0.72    |
| Recall (1)     | 0.43    |

> üîç *La m√©trica AUC = 0.74 sugiere una buena capacidad de discriminaci√≥n para predecir impagos, aunque con espacio para mejora en recall.*

### üìâ Curvas de entrenamiento (Loss y Accuracy)

El comportamiento del entrenamiento para la arquitectura ResNet tabular muestra una mejora progresiva en ambas m√©tricas (p√©rdida y precisi√≥n), tanto en los datos de entrenamiento como validaci√≥n.

üìä Gr√°fico de curvas:  
![Curvas Loss y Accuracy - ResNet](outputs_credit/resnet__lr0.001__bs256__ep50_curves.png)

**An√°lisis**:

- **Loss**:
  - Se observa una disminuci√≥n constante de la p√©rdida en entrenamiento, lo cual es esperable.
  - La p√©rdida de validaci√≥n muestra una tendencia descendente hasta estabilizarse cerca del epoch 13, sin evidencia fuerte de sobreajuste.
  
- **Accuracy**:
  - La precisi√≥n en validaci√≥n mejora r√°pidamente en las primeras 5 √©pocas.
  - Luego se estabiliza entre 71% y 73%, mientras que en entrenamiento contin√∫a creciendo hasta rozar el 80%.
  - La separaci√≥n moderada sugiere **una ligera sobre-adaptaci√≥n al conjunto de entrenamiento**, aunque dentro de m√°rgenes aceptables.

> üí° *Este patr√≥n sugiere que el modelo es capaz de aprender de forma efectiva sin caer en sobreajuste prematuro. Podr√≠a beneficiarse de m√°s regularizaci√≥n o early stopping m√°s agresivo si se desea evitar esta separaci√≥n.*


### üßæ Matriz de confusi√≥n

|                 | Pred No-Impago (0) | Pred Impago (1) |
|-----------------|--------------------|------------------|
| **Real No-Impago (0)** | 130                | 10               |
| **Real Impago (1)**    | 34                 | 26               |

üìå Visualizaci√≥n:  
![Confusion Matrix](outputs_credit/resnet__lr0.001__bs256__ep50_cm.png)

### üìà Curva ROC - ResNet Tabular

La curva ROC (Receiver Operating Characteristic) nos permite evaluar el rendimiento del modelo sin depender de un umbral de clasificaci√≥n fijo.

üìä Gr√°fico ROC:  
![Curva ROC - ResNet](outputs_credit/resnet__lr0.001__bs256__ep50_roc.png)

**An√°lisis**:

- La curva ROC del modelo ResNet muestra una buena separaci√≥n entre clases.
- El √°rea bajo la curva (AUC) es considerablemente superior a 0.8, lo que indica una capacidad discriminativa s√≥lida.
- La forma escalonada es esperable dado el tama√±o reducido del set de test (discreto), y no compromete la calidad general de la predicci√≥n.

> ‚úÖ *Este resultado confirma que el modelo es robusto al momento de distinguir correctamente entre clientes que pagar√°n (clase 0) y aquellos con riesgo de impago (clase 1).*



### üí∞ An√°lisis de costos
Dado un costo de:
- `FP = 1.0` (rechazar cliente bueno)
- `FN = 5.0` (aceptar cliente moroso)

üì¶ Resultado del an√°lisis (ver [`costs.json`](outputs_credit/resnet__lr0.001__bs256__ep50_costs.json)):

- TP: 26  
- FP: 10  
- FN: 34  
- TN: 130  
- Costo total estimado: **180.0 unidades**

> ‚ùó *El alto n√∫mero de falsos negativos (FN = 34) incrementa fuertemente el costo operativo.*

### üß† Interpretabilidad con SHAP

El resumen de importancia de variables mediante SHAP (`KernelExplainer`) muestra las variables que m√°s influyen en las predicciones de impago.

üìä SHAP summary plot:  
![SHAP Summary](outputs_credit/resnet__lr0.001__bs256__ep50_shap_summary.png)

### üß© Conclusi√≥n parcial

- ResNet ofrece **una arquitectura m√°s profunda y regularizada**, lo que contribuye a una mayor capacidad de generalizaci√≥n respecto a un DNN simple.
- Presenta un **mejor AUC y precisi√≥n**, pero a√∫n tiene **limitaciones en recall**, lo que impacta directamente en el costo asociado a falsos negativos.
- Recomendaci√≥n: aplicar **ajuste del umbral de decisi√≥n**, t√©cnicas de balanceo adicionales, o reforzar la arquitectura con TabNet o ensamblado con XGBoost para mitigar los FN.

---


## üìä Explicabilidad, Evaluaci√≥n y Reflexi√≥n Cr√≠tica

### 4Ô∏è‚É£ Explicabilidad del Modelo
- **SHAP**: el an√°lisis con *SHAP summary plots* revela que las variables m√°s influyentes en la predicci√≥n de impago son **`duration_months`**, **`credit_amount`** y ciertos indicadores categ√≥ricos relacionados con el historial crediticio.  
  - Ejemplo: mayor duraci√≥n del cr√©dito y montos m√°s altos se asocian con un aumento en la probabilidad de impago.  
- **LIME**: permite interpretar casos individuales, mostrando c√≥mo cada variable concreta influye en la decisi√≥n final del modelo (explicabilidad local). Esto es cr√≠tico en contexto bancario, donde cada decisi√≥n de cr√©dito debe poder justificarse.

üìå *Conclusi√≥n*: El modelo no solo predice, sino que tambi√©n explica **qu√© factores empujan una solicitud hacia aprobaci√≥n o rechazo**, facilitando la comunicaci√≥n con equipos de riesgo.

---

### 5Ô∏è‚É£ Evaluaci√≥n de M√©tricas
- **M√©tricas globales**:  
  - Precisi√≥n: entre *0.70‚Äì0.80* seg√∫n arquitectura.  
  - Recall: moderado, captando un porcentaje relevante de los casos de impago.  
  - F1-score: balance adecuado entre precisi√≥n y recall.  
  - ROC-AUC: superior a **0.80**, confirmando buena discriminaci√≥n entre clases.

- **Errores tipo I y II en contexto financiero**:  
  - **Error Tipo I (falsos positivos)**: clientes clasificados como ‚Äúimpago‚Äù cuando en realidad cumplen. Impacto ‚Üí *p√©rdida de oportunidades de negocio* y clientes insatisfechos.  
  - **Error Tipo II (falsos negativos)**: clientes clasificados como ‚Äúno impago‚Äù cuando en realidad incumplen. Impacto ‚Üí *p√©rdida econ√≥mica directa para la entidad financiera*.  
  - Dado el costo mayor del **Error Tipo II**, en el an√°lisis de costos se penaliz√≥ m√°s este escenario, para reflejar el riesgo real en decisiones crediticias.

üìå *Conclusi√≥n*: El modelo logra un equilibrio aceptable, pero puede ajustarse el **umbral de decisi√≥n** para priorizar la reducci√≥n de falsos negativos en escenarios de mayor riesgo.

---

### 6Ô∏è‚É£ Reflexi√≥n Cr√≠tica y √âtica
- **Sesgos posibles**: si el dataset contiene variables proxy de g√©nero, edad o etnia, el modelo puede aprender discriminaciones indirectas.  
- **√âtica en la pr√°ctica**: es fundamental que las decisiones no sean una ‚Äúcaja negra‚Äù; por ello se incorporaron m√©todos de explicabilidad (SHAP/LIME) que permiten auditar cada decisi√≥n.  
- **Explicabilidad para el equipo de riesgo**: gracias a los gr√°ficos de importancia de variables y explicaciones locales, se pueden comunicar las decisiones de manera comprensible a no t√©cnicos, mostrando por qu√© una solicitud fue rechazada.  
- **Recomendaci√≥n institucional**: acompa√±ar el uso del modelo con pol√≠ticas de revisi√≥n humana y auditor√≠a de decisiones cr√≠ticas, evitando sesgos sistem√°ticos y asegurando transparencia.

üìå *Resumen ejecutivo*:  
El modelo DNN/ResNet para scoring crediticio alcanza un rendimiento s√≥lido (AUC > 0.8), incorpora t√©cnicas de regularizaci√≥n y explicabilidad, y permite comprender los factores determinantes de cada decisi√≥n. A nivel √©tico y de negocio, debe priorizar la reducci√≥n de **falsos negativos** (para evitar p√©rdidas financieras), al tiempo que garantiza transparencia ante clientes y reguladores.


