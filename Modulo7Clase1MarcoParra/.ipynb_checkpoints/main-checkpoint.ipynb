{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCCu9jVwWuW7",
    "outputId": "bb092a2a-0643-43fd-c744-32a7c8a006b8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rF-OMnNDZvOF"
   },
   "outputs": [],
   "source": [
    "# Pinea versiones compatibles con el Colab actual\n",
    "!pip -q install \"tensorflow==2.19.0\" \"tf-keras==2.19.0\" \"tensorflow-text==2.19.0\" \"tensorflow-decision-forests==1.12.0\" \"numpy==2.0.2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "V7NhDkR9Zo-o",
    "outputId": "fa3a1e7e-85f3-4345-f773-0ab3129cc77e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 19:32:55.701650: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-16 19:32:55.738217: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-16 19:32:55.739170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-16 19:32:56.455753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.13.1\n",
      "GPU disponible?: False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "No existe PROJECT_ROOT: /content/drive/MyDrive/EspecialidadML/Modulo7Clase1MarcoParra",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 3) Preparar entorno de importación y cwd\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(PROJECT_ROOT), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo existe PROJECT_ROOT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPROJECT_ROOT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PROJECT_ROOT \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n\u001b[1;32m     28\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, PROJECT_ROOT)\n",
      "\u001b[0;31mAssertionError\u001b[0m: No existe PROJECT_ROOT: /content/drive/MyDrive/EspecialidadML/Modulo7Clase1MarcoParra"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# COLAB RUNNER — Proyecto Especialidad ML (Fashion-MNIST, MLP)\n",
    "# (versión GRID: cumple enunciado 2 pérdidas × 2 optimizadores y activaciones distintas)\n",
    "# ------------------------------------------------------------\n",
    "# Pasos:\n",
    "#  1) Ajusta PROJECT_ROOT a la ruta de tu carpeta en Drive.\n",
    "#  2) Ejecuta esta celda (Runtime -> GPU activado).\n",
    "#  3) El grid guardará artefactos en outputs/ y aquí se listan/visualizan.\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "# 1) ⚠️ EDITA ESTA RUTA a TU carpeta del proyecto en Drive\n",
    "#    Ejemplos:\n",
    "#    \"/content/drive/MyDrive/Modulo7Clase1MarcoParra\"\n",
    "#    \"/content/drive/Shareddrives/<Tu_Unidad_Compartida>/Modulo7Clase1MarcoParra\"\n",
    "PROJECT_ROOT = \"/content/drive/MyDrive/EspecialidadML/Modulo7Clase1MarcoParra\"  # <-- CAMBIA AQUÍ\n",
    "\n",
    "# 2) Verificar TF/GPU (usa versiones de Colab por defecto para evitar conflictos)\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPU disponible?:\", bool(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# 3) Preparar entorno de importación y cwd\n",
    "import os, sys, glob\n",
    "assert os.path.isdir(PROJECT_ROOT), f\"No existe PROJECT_ROOT: {PROJECT_ROOT}\"\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(\"Working dir:\", os.getcwd())\n",
    "print(\"Árbol (primeros niveles):\")\n",
    "!find . -maxdepth 3 -type f -print | sed -n '1,200p'\n",
    "\n",
    "# 4) Imports del proyecto (grid + utils) — SIN duplicar lógica\n",
    "from src.utils.preprocessing import load_preprocess\n",
    "from src.experiments.grid import run_grid  # el grid entrena/evalúa y llama a visualizer internamente\n",
    "\n",
    "# 5) Cargar datos UNA sola vez (normaliza [0,1] + one-hot)\n",
    "(x_train, y_train), (x_test, y_test) = load_preprocess(\n",
    "    dataset=\"fashion\",\n",
    "    one_hot=True,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# 6) Ejecutar GRID (no grafica aquí; genera artefactos en outputs/)\n",
    "out_dir = \"outputs\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "results = run_grid(\n",
    "    data=(x_train, y_train, x_test, y_test),\n",
    "    epochs=10,              # 5–10 según enunciado\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    out_dir=out_dir,\n",
    "    expected_range=(0.88, 0.92)  # típico para MLP en Fashion-MNIST\n",
    ")\n",
    "\n",
    "# 7) (Opcional) Mostrar artefactos generados\n",
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "print(\"\\nArchivos en outputs/:\")\n",
    "for p in sorted(glob.glob(os.path.join(out_dir, \"*\"))):\n",
    "    print(\" -\", os.path.basename(p))\n",
    "\n",
    "# Mostrar comparación general si existe\n",
    "cmp_png = os.path.join(out_dir, \"experiments_comparison.png\")\n",
    "if os.path.isfile(cmp_png):\n",
    "    display(Image(filename=cmp_png))\n",
    "\n",
    "# Mostrar reflexión automática\n",
    "refl_md = os.path.join(out_dir, \"reflection_enunciado.md\")\n",
    "if os.path.isfile(refl_md):\n",
    "    with open(refl_md, \"r\", encoding=\"utf-8\") as f:\n",
    "        display(Markdown(f.read()))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
