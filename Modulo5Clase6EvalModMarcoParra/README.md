# ğŸ“Œ Proyecto: Scoring Crediticio con Interpretabilidad

## ğŸ¯ Objetivo
Construir un modelo predictivo para el scoring crediticio usando tÃ©cnicas de regularizaciÃ³n
(Lasso/Ridge) y aplicar interpretabilidad con **SHAP** y **LIME**.

## ğŸ“‚ Estructura del Proyecto
```
â”œâ”€â”€ data/                # Dataset raw y procesados
â”œâ”€â”€ notebooks/           # Jupyter Notebooks
â”œâ”€â”€ outputs/             # GrÃ¡ficos, reportes y resultados
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ main.py          # Pipeline principal
â”‚   â””â”€â”€ crear_notebook.py # Generar notebook desde main
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py         # Carga y preprocesamiento
â”‚   â”œâ”€â”€ modelos.py       # DefiniciÃ³n y entrenamiento de modelos
â”‚   â”œâ”€â”€ evaluador.py     # EvaluaciÃ³n de mÃ©tricas
â”‚   â”œâ”€â”€ visualizador.py  # Visualizaciones
â”‚   â””â”€â”€ interpretabilidad.py # SHAP y LIME
â”œâ”€â”€ docs/                # Informe tÃ©cnico
â”œâ”€â”€ environment.yml      # Dependencias conda
â””â”€â”€ README.md
```

## âš™ï¸ Flujo del Proyecto
1. **Carga y preprocesamiento** del dataset `credit` de OpenML.
2. **Entrenamiento** con regresiÃ³n logÃ­stica y Random Forest, aplicando Lasso y Ridge.
3. **EvaluaciÃ³n** con Accuracy, Recall, F1 y AUC.
4. **Interpretabilidad** usando SHAP y LIME.
5. **VisualizaciÃ³n** de mÃ©tricas y explicaciones.
6. **AnÃ¡lisis crÃ­tico** y elaboraciÃ³n del informe tÃ©cnico.

## ğŸš€ CÃ³mo iniciar
```bash
bash setup_scoring_project.sh
conda env create -f environment.yml
conda activate especialidadmachinelearning
python -m scripts.main
```

---

# ğŸ“Š Proyecto: Scoring Crediticio con Modelos Predictivos

## ğŸ“Œ IntroducciÃ³n

El presente proyecto tiene como objetivo **predecir el riesgo crediticio de clientes** utilizando el dataset `credit` de OpenML. Se busca clasificar a los clientes en **alto riesgo (1)** y **bajo riesgo (0)**, aplicando modelos de clasificaciÃ³n con **regularizaciÃ³n** y tÃ©cnicas de evaluaciÃ³n rigurosas.

La motivaciÃ³n radica en la relevancia del **scoring crediticio** para instituciones financieras, donde la precisiÃ³n y la interpretabilidad de los modelos son fundamentales para la toma de decisiones.

---

## ğŸ¯ Objetivos

1. **Preprocesamiento de datos**: limpieza, codificaciÃ³n y escalamiento.
2. **Entrenamiento de modelos**:

   * **Logistic Regression** con regularizaciÃ³n L1 y L2.
   * **Random Forest** con ajuste de hiperparÃ¡metros.
3. **EvaluaciÃ³n del rendimiento** mediante:

   * Accuracy, Precision, Recall, F1-Score y AUC.
   * Matriz de confusiÃ³n y curva ROC.
4. **Interpretabilidad**: anÃ¡lisis de coeficientes e importancia de variables.
5. **ComparaciÃ³n de modelos** y conclusiones finales.

---

## âš™ï¸ TecnologÃ­as Utilizadas

* **Python 3.8**
* **scikit-learn**
* **pandas, numpy**
* **matplotlib, seaborn**
* **GridSearchCV** para selecciÃ³n de hiperparÃ¡metros

---

## ğŸ“Š Resultados

### ğŸ“Œ Tabla comparativa de mÃ©tricas

| Modelo              | Accuracy | Precision | Recall | F1-Score | AUC   |
| ------------------- | -------- | --------- | ------ | -------- | ----- |
| Random Forest       | 0.779    | 0.787     | 0.764  | 0.775    | 0.858 |
| Logistic Regression | 0.729    | 0.783     | 0.633  | 0.700    | 0.794 |

---

### ğŸŒ² Random Forest

* **Importancia de variables**

  ![Feature Importance - RandomForest](outputs/feature_importance_randomforest.png)

* **Curva ROC**

  ![ROC Curve - RandomForest](outputs/roc_curve_randomforest.png)

* **Matriz de ConfusiÃ³n**

  ![Confusion Matrix - RandomForest](outputs/confusion_matrix_randomforest.png)

---

### ğŸ“‰ Logistic Regression

* **Coeficientes del modelo**

  ![Coeficientes - LogisticRegression](outputs/coeficientes_logisticregression.png)

* **Curva ROC**

  ![ROC Curve - LogisticRegression](outputs/roc_curve_logisticregression.png)

* **Matriz de ConfusiÃ³n**

  ![Confusion Matrix - LogisticRegression](outputs/confusion_matrix_logisticregression.png)

---

## ğŸ“Œ AnÃ¡lisis Comparativo

* **Random Forest** alcanzÃ³ **mayor AUC (0.86)**, superando a Logistic Regression (**0.79**). Esto indica mejor capacidad de discriminaciÃ³n.
* En **accuracy y F1-score**, Random Forest tambiÃ©n fue superior (0.779 vs 0.729 y 0.775 vs 0.700).
* **Logistic Regression** es mÃ¡s interpretable gracias a sus coeficientes, mostrando que las variables relacionadas con atrasos en pagos tienen mayor peso.
* **Random Forest** identificÃ³ como variables mÃ¡s relevantes la **utilizaciÃ³n de lÃ­neas de crÃ©dito** y el **historial de pagos atrasados**.
* La **matriz de confusiÃ³n** mostrÃ³ que Random Forest redujo falsos positivos respecto a Logistic Regression.

---

## ğŸ“Œ Resumen Ejecutivo

1. **Random Forest es el modelo mÃ¡s robusto** para predecir riesgo crediticio, alcanzando un AUC de 0.86 y mejorando recall y precisiÃ³n.
2. **Logistic Regression sigue siendo Ãºtil** para interpretabilidad, permitiendo explicar quÃ© variables impulsan las decisiones.
3. Se recomienda usar **Random Forest en producciÃ³n**, acompaÃ±ado de **Logistic Regression para auditorÃ­as y explicaciones regulatorias**.
4. La interpretabilidad es clave en aplicaciones de scoring crediticio: ambas tÃ©cnicas se complementan, maximizando precisiÃ³n y transparencia.

---
