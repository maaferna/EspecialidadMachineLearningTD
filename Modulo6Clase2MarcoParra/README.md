# ğŸ“Œ Proyecto: Clustering Basado en Densidad (DBSCAN y HDBSCAN)

## ğŸ“– Resumen Ejecutivo

Este proyecto tiene como objetivo **aplicar, comparar y evaluar algoritmos de clustering basados en densidad** sobre datasets con estructuras complejas y presencia de ruido. Se implementaron **DBSCAN** y **HDBSCAN** para identificar grupos sin necesidad de especificar previamente el nÃºmero de clusters. El anÃ¡lisis incluye la **reducciÃ³n de dimensionalidad con PCA**, la **evaluaciÃ³n objetiva mediante mÃ©tricas de silueta e Ã­ndice de Davies-Bouldin**, y la **visualizaciÃ³n en 2D** para interpretar los resultados. Finalmente, se presenta una **comparaciÃ³n entre ambos algoritmos**, destacando sus fortalezas y limitaciones.

---

## ğŸ¯ Objetivos del Proyecto

1. **Carga de datos**

   * Utilizar datasets adecuados para clustering no supervisado:

     * Generados artificialmente (`make_moons`, `make_blobs`, `make_circles`).
     * Dataset real de vinos (`load_wine` de Scikit-learn).

2. **Preprocesamiento**

   * Escalar los datos con `StandardScaler`.
   * Aplicar PCA en caso de alto nÃºmero de variables, para simplificar la visualizaciÃ³n.

3. **Clustering basado en densidad**

   * Implementar **DBSCAN** con diferentes configuraciones de `eps` y `min_samples`.
   * Implementar **HDBSCAN** sin necesidad de ajuste manual de parÃ¡metros.

4. **EvaluaciÃ³n de modelos**

   * Calcular el **Ã­ndice de silueta** (`silhouette_score`).
   * Calcular el **Ã­ndice de Davies-Bouldin** (`davies_bouldin_score`).
   * Analizar las diferencias entre ambos algoritmos.

5. **VisualizaciÃ³n de resultados**

   * Generar grÃ¡ficos en 2D mostrando los clusters formados.
   * Comparar cÃ³mo DBSCAN y HDBSCAN tratan el ruido y la forma de los clusters.

6. **Conclusiones**

   * Identificar quÃ© algoritmo funcionÃ³ mejor en cada caso y por quÃ©.
   * Discutir las limitaciones encontradas y posibles mejoras futuras.

---

## ğŸ§© Stack TecnolÃ³gico

* **Lenguaje**: Python 3.8+
* **LibrerÃ­as principales**:

  * `scikit-learn` â†’ generaciÃ³n de datasets, escalado, PCA, DBSCAN.
  * `hdbscan` â†’ implementaciÃ³n de HDBSCAN.
  * `matplotlib`, `seaborn` â†’ visualizaciÃ³n.
  * `numpy`, `pandas` â†’ manipulaciÃ³n de datos.

---

## ğŸ“‚ Estructura del Proyecto

```
ğŸ“ ClusteringDensidad/
â”‚
â”œâ”€â”€ ğŸ“ scripts/
â”‚   â””â”€â”€ main.py                # Pipeline principal
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ utils.py               # Carga y preprocesamiento de datasets
â”‚   â”œâ”€â”€ modelos.py             # ImplementaciÃ³n de DBSCAN y HDBSCAN
â”‚   â”œâ”€â”€ evaluador.py           # CÃ¡lculo de mÃ©tricas de evaluaciÃ³n
â”‚   â””â”€â”€ visualizador.py        # GrÃ¡ficas comparativas de clusters
â”‚
â”œâ”€â”€ ğŸ“ outputs/                # Resultados generados
â”‚   â”œâ”€â”€ clusters_dbscan.png
â”‚   â”œâ”€â”€ clusters_hdbscan.png
â”‚   â”œâ”€â”€ comparacion_metricas.csv
â”‚
â”œâ”€â”€ environment.yml            # Entorno Conda con dependencias
â””â”€â”€ create_notebook.py         # Script para generar notebook con resultados
```


---


## ğŸ“Š Resultados â€“ DBSCAN

### 1ï¸âƒ£ IntroducciÃ³n al experimento

El algoritmo **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** se probÃ³ sobre el dataset *Wine* preprocesado, aplicando escalado **MinMaxScaler** y reduciendo dimensionalidad para visualizaciÃ³n en dos ejes (`alcohol` y `malic_acid`).

Se evaluaron diferentes combinaciones de parÃ¡metros clave:

* **`eps`**: distancia mÃ¡xima para considerar puntos como vecinos.
* **`min_samples`**: nÃºmero mÃ­nimo de vecinos requeridos para formar un nÃºcleo de clÃºster.

### 2ï¸âƒ£ Observaciones generales

En todas las combinaciones probadas, **el algoritmo detectÃ³ un Ãºnico clÃºster (etiqueta 0)**, sin diferenciar subgrupos. Esto indica que:

* Con las distancias y densidades actuales, DBSCAN no encuentra regiones con densidad lo suficientemente distinta como para separar en mÃ¡s clÃºsteres.
* Los valores de `eps` seleccionados (0.3, 0.5, 0.7) y `min_samples` (3, 5, 10) no producen cambios significativos en la estructura de agrupamiento.

### 3ï¸âƒ£ AnÃ¡lisis por configuraciÃ³n

#### ğŸ”¹ `eps = 0.3`

* **min\_samples = 3, 5, 10** â†’ No hay separaciÃ³n clara de grupos, todos los puntos pertenecen al mismo clÃºster.
* Un valor tan bajo de `eps` limita el alcance de cada punto, pero en este dataset las distancias no generan densidad suficiente para separar grupos.

#### ğŸ”¹ `eps = 0.5`

* **min\_samples = 3, 5, 10** â†’ El resultado es idÃ©ntico al caso anterior: un Ãºnico clÃºster.
* El ligero aumento de `eps` tampoco es suficiente para abarcar mÃ¡s puntos y formar subgrupos.

#### ğŸ”¹ `eps = 0.7`

* **min\_samples = 3, 5, 10** â†’ Se mantiene la situaciÃ³n: un Ãºnico clÃºster.
* Aunque el radio de bÃºsqueda es mayor, la distribuciÃ³n de datos sigue siendo homogÃ©nea en tÃ©rminos de densidad, impidiendo la detecciÃ³n de fronteras naturales.

### 4ï¸âƒ£ InterpretaciÃ³n

El comportamiento observado sugiere que:

* El dataset *Wine*, en las dimensiones seleccionadas (`alcohol` y `malic_acid`), **no presenta densidades locales suficientemente contrastadas** para que DBSCAN identifique mÃ¡s de un grupo.
* Este resultado pone en evidencia la **sensibilidad de DBSCAN a la escala de los datos y a la selecciÃ³n de `eps`**, asÃ­ como la necesidad de evaluar mÃ¡s dimensiones (por ejemplo, aplicando PCA antes de DBSCAN) para descubrir patrones mÃ¡s complejos.


---


## ğŸ“Š Resultados y AnÃ¡lisis Comparativo

### Objetivo Recordatorio

El objetivo de este proyecto fue **aplicar, comparar y evaluar modelos de clustering basados en densidad** â€”DBSCAN y HDBSCANâ€” sobre el dataset **Wine** (preprocesado con escalado y reducciÃ³n de dimensionalidad mediante PCA), evaluando el rendimiento con mÃ©tricas objetivas (Ãndice de Silueta y Davies-Bouldin) y mediante visualizaciones en 2D/3D, incluyendo PCA y t-SNE.

---

### 1ï¸âƒ£ Resultados de DBSCAN

Se evaluaron mÃºltiples combinaciones de parÃ¡metros `eps` y `min_samples` para DBSCAN, con el fin de observar la sensibilidad del algoritmo a estos hiperparÃ¡metros.

#### ğŸ“Œ Observaciones clave:

* En **todas las configuraciones** (ver Figuras [`dbscan_eps*.png`](outputs/)), DBSCAN tendiÃ³ a asignar todos los puntos a un Ãºnico cluster (etiqueta 0), sin identificar subgrupos claros.
* Esto sugiere que, con la estructura actual de los datos (13 features reducidos por PCA a 2D para visualizaciÃ³n), las distancias entre puntos no son lo suficientemente diferentes como para que DBSCAN detecte zonas de densidad distintas.
* El t-SNE aplicado sobre los resultados de DBSCAN (ver Figuras [`tsne_dbscan_eps*.png`](outputs/)) confirmÃ³ que el espacio embebido no mostrÃ³ agrupaciones claras, evidenciando que DBSCAN no logrÃ³ separar patrones relevantes en este dataset sin un ajuste mÃ¡s agresivo de parÃ¡metros.

 

#### ğŸ“Š Tablas asociadas:

* [**DBSCAN\_consolidado.csv**](outputs/DBSCAN_consolidado.csv): contiene el Ã­ndice de silueta y Davies-Bouldin para cada combinaciÃ³n de parÃ¡metros, confirmando valores de silueta cercanos a 0 y Davies-Bouldin altos, lo que refleja baja calidad de clustering.

---

### 2ï¸âƒ£ Resultados de HDBSCAN

Se probÃ³ HDBSCAN con diferentes valores de `min_cluster_size` (5 y 10).

#### ğŸ“Œ Observaciones clave:

* A diferencia de DBSCAN, **HDBSCAN sÃ­ identificÃ³ mÃºltiples clusters** en ambas configuraciones (ver Figuras [`hdbscan_mincluster*.png`](outputs/)).
* DetectÃ³ entre 3 y 4 clusters principales, junto con algunos puntos clasificados como ruido (etiqueta `-1`).
* Esto es consistente con la naturaleza jerÃ¡rquica de HDBSCAN, que permite detectar clusters de distinta densidad sin necesidad de definir `eps` manualmente.
* El t-SNE aplicado a HDBSCAN (ver Figuras [`tsne_hdbscan_mincluster*.png`](outputs/)) mostrÃ³ una mejor separaciÃ³n entre grupos en el espacio reducido, reforzando la idea de que HDBSCAN modelÃ³ mejor la estructura latente.

#### ğŸ“Š Tablas asociadas:

* [**HDBSCAN\_consolidado.csv**](outputs/HDBSCAN_consolidado.csv): refleja Ã­ndices de silueta mÃ¡s altos y Davies-Bouldin mÃ¡s bajos que DBSCAN, indicando una mejor calidad de agrupamiento.

---

### 3ï¸âƒ£ Comparativa PCA vs. Clustering Basado en Densidad

El PCA 2D del dataset (Figura [`pca_2d.png`](outputs/pca_2d.png)) muestra claramente que existen **tres grupos naturales** en el espacio reducido, que corresponden a las clases originales del dataset Wine.

* **DBSCAN** no logrÃ³ identificar estos tres grupos, probablemente porque la mÃ©trica de distancia en el espacio completo de features no reflejaba la estructura que sÃ­ es visible tras PCA.
* **HDBSCAN** se acercÃ³ mÃ¡s a la estructura esperada, detectando subgrupos que se alinean parcialmente con los grupos del PCA.

---

### 4ï¸âƒ£ Conclusiones

1. **DBSCAN** fue muy sensible a la elecciÃ³n de parÃ¡metros y, en este caso, no logrÃ³ segmentar los datos en clusters significativos, resultando en una Ãºnica clase para la mayorÃ­a de configuraciones.
2. **HDBSCAN** mostrÃ³ mayor robustez, detectando varios clusters sin necesidad de ajustar manualmente `eps` y con mejor alineaciÃ³n a la estructura real del dataset.
3. La visualizaciÃ³n con **PCA** y **t-SNE** evidenciÃ³ que los datos tienen una estructura subyacente que HDBSCAN captura mejor que DBSCAN.
4. Para datasets con ruido y clusters de distinta densidad, **HDBSCAN** es preferible a DBSCAN, especialmente cuando no se conoce un `eps` Ã³ptimo.
5. En un flujo DSNA (Data Science for Non-Analysts), este tipo de anÃ¡lisis comparativo ayuda a seleccionar un algoritmo de clustering mÃ¡s interpretable y efectivo.

---
# AnÃ¡lisis de Clustering en Dataset Wine ğŸ“Š

Este repositorio contiene los resultados del anÃ¡lisis de clustering utilizando **DBSCAN** y **HDBSCAN** en el dataset Wine.  
Se evaluaron distintas configuraciones de parÃ¡metros y se visualizaron los resultados mediante **PCA 2D** y **t-SNE**.

---

## Resultados - DBSCAN ğŸ¯

### Configuraciones Evaluadas
- eps = 0.3 con min_samples = 3, 5, 10
- eps = 0.5 con min_samples = 3, 5, 10
- eps = 0.7 con min_samples = 3, 5, 10

### Visualizaciones DBSCAN

1. **eps=0.3, min_samples=3**  
   ![DBSCAN eps=0.3 min=3](outputs/dbscan_eps0.3_min3.png)

2. **eps=0.3, min_samples=5**  
   ![DBSCAN eps=0.3 min=5](outputs/dbscan_eps0.3_min5.png)

3. **eps=0.3, min_samples=10**  
   ![DBSCAN eps=0.3 min=10](outputs/dbscan_eps0.3_min10.png)

4. **eps=0.5, min_samples=3**  
   ![DBSCAN eps=0.5 min=3](outputs/dbscan_eps0.5_min3.png)

5. **eps=0.5, min_samples=5**  
   ![DBSCAN eps=0.5 min=5](outputs/dbscan_eps0.5_min5.png)

6. **eps=0.5, min_samples=10**  
   ![DBSCAN eps=0.5 min=10](outputs/dbscan_eps0.5_min10.png)

7. **eps=0.7, min_samples=3**  
   ![DBSCAN eps=0.7 min=3](outputs/dbscan_eps0.7_min3.png)

8. **eps=0.7, min_samples=5**  
   ![DBSCAN eps=0.7 min=5](outputs/dbscan_eps0.7_min5.png)

9. **eps=0.7, min_samples=10**  
   ![DBSCAN eps=0.7 min=10](outputs/dbscan_eps0.7_min10.png)

---

## Resultados - HDBSCAN ğŸŒ³

### Configuraciones Evaluadas
- min_cluster_size = 5
- min_cluster_size = 10

### Visualizaciones HDBSCAN

1. **min_cluster_size=5**  
   ![HDBSCAN min_cluster_size=5](outputs/hdbscan_mincluster5.png)

2. **min_cluster_size=10**  
   ![HDBSCAN min_cluster_size=10](outputs/hdbscan_mincluster10.png)

---

## Visualizaciones t-SNE ğŸ§©

### t-SNE DBSCAN
- eps=0.3, min_samples=3 â†’ ![t-SNE DBSCAN eps=0.3 min=3](outputs/tsne_dbscan_eps0.3_min3.png)  
- eps=0.3, min_samples=5 â†’ ![t-SNE DBSCAN eps=0.3 min=5](outputs/tsne_dbscan_eps0.3_min5.png)  
- eps=0.3, min_samples=10 â†’ ![t-SNE DBSCAN eps=0.3 min=10](outputs/tsne_dbscan_eps0.3_min10.png)  
- eps=0.5, min_samples=3 â†’ ![t-SNE DBSCAN eps=0.5 min=3](outputs/tsne_dbscan_eps0.5_min3.png)  
- eps=0.5, min_samples=5 â†’ ![t-SNE DBSCAN eps=0.5 min=5](outputs/tsne_dbscan_eps0.5_min5.png)  
- eps=0.5, min_samples=10 â†’ ![t-SNE DBSCAN eps=0.5 min=10](outputs/tsne_dbscan_eps0.5_min10.png)  
- eps=0.7, min_samples=3 â†’ ![t-SNE DBSCAN eps=0.7 min=3](outputs/tsne_dbscan_eps0.7_min3.png)  
- eps=0.7, min_samples=5 â†’ ![t-SNE DBSCAN eps=0.7 min=5](outputs/tsne_dbscan_eps0.7_min5.png)  
- eps=0.7, min_samples=10 â†’ ![t-SNE DBSCAN eps=0.7 min=10](outputs/tsne_dbscan_eps0.7_min10.png)  

### t-SNE HDBSCAN
- min_cluster_size=5 â†’ ![t-SNE HDBSCAN min_cluster_size=5](outputs/tsne_hdbscan_mincluster5.png)  
- min_cluster_size=10 â†’ ![t-SNE HDBSCAN min_cluster_size=10](outputs/tsne_hdbscan_mincluster10.png)  

---

## PCA 2D ğŸ“‰
![PCA 2D Visualization](outputs/pca_2d.png)

---

## Datos Consolidados ğŸ“‚
- [DBSCAN_consolidado.csv](outputs/DBSCAN_consolidado.csv) â†’ MÃ©tricas para todas las configuraciones DBSCAN  
- [HDBSCAN_consolidado.csv](outputs/HDBSCAN_consolidado.csv) â†’ MÃ©tricas para configuraciones HDBSCAN



## ğŸ“ Conclusiones

* **DBSCAN** es muy Ãºtil para detectar clusters de forma arbitraria, pero su rendimiento depende fuertemente de los parÃ¡metros `eps` y `min_samples`.
* **HDBSCAN** ofrece mayor robustez al no requerir ajuste manual, adaptÃ¡ndose mejor a datasets con ruido o estructuras complejas.
* El **Ã­ndice de silueta** y el **Ã­ndice de Davies-Bouldin** permitieron validar objetivamente las agrupaciones, mostrando que **HDBSCAN suele generar clusters mÃ¡s naturales y estables**.
* Este estudio demuestra la importancia de combinar **mÃ©tricas objetivas** con **visualizaciones exploratorias** para interpretar adecuadamente los resultados de clustering no supervisado.
