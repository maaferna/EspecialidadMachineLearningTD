# üìä Comparaci√≥n de M√©todos de Optimizaci√≥n en Regresi√≥n Lineal

Este proyecto implementa y compara distintos m√©todos de optimizaci√≥n para minimizar una funci√≥n de costo en un problema de **regresi√≥n lineal**.

Se eval√∫an dos t√©cnicas cl√°sicas:
- **Gradient Descent (GD)**
- **Stochastic Gradient Descent (SGD)**

Y se analizan en t√©rminos de:
- Convergencia del error (MSE)
- Evoluci√≥n de par√°metros (pendiente `w` y sesgo `b`)
- Estabilidad del entrenamiento

---

## üéØ Objetivo

Aplicar y comparar algoritmos de optimizaci√≥n sobre una funci√≥n de costo en regresi√≥n lineal:
- Generar datos sint√©ticos con ruido
- Definir y derivar la funci√≥n de costo (MSE)
- Calcular gradientes
- Aplicar GD y SGD para minimizar el error
- Visualizar y analizar los resultados

---

## üß† Stack Tecnol√≥gico

- **Python 3.8**
- **NumPy**: manipulaci√≥n matem√°tica
- **Matplotlib**: visualizaci√≥n
- **Conda** (opcional): manejo de entorno virtual

---

## üìÇ Estructura del Proyecto

```

Modulo3EvalMod\_MarcoParra/
‚îú‚îÄ‚îÄ environment.yml            # Dependencias Conda (auto-generado)
‚îú‚îÄ‚îÄ init\_project.sh           # Script para crear estructura del proyecto
‚îú‚îÄ‚îÄ README.md                 # Este archivo
‚îú‚îÄ‚îÄ notebooks/                # Notebooks generados autom√°ticamente
‚îÇ   ‚îî‚îÄ‚îÄ comparacion\_regresion.ipynb
‚îú‚îÄ‚îÄ outputs/                  # Resultados (gr√°ficos)
‚îÇ   ‚îî‚îÄ‚îÄ comparacion\_gd\_sgd.png
‚îú‚îÄ‚îÄ scripts/                  # Punto de entrada principal
‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ src/                      # C√≥digo modular del proyecto
‚îú‚îÄ‚îÄ datos.py              # Generaci√≥n de datos sint√©ticos
‚îú‚îÄ‚îÄ optimizadores.py      # Implementaci√≥n de GD y SGD
‚îú‚îÄ‚îÄ utils.py              # MSE y c√°lculo de gradientes
‚îî‚îÄ‚îÄ visualizador.py       # Funciones gr√°ficas

````

---

## ‚öôÔ∏è Instalaci√≥n

### ‚úÖ Opci√≥n 1: Usando Conda (recomendado)

```bash
conda env create -f environment.yml
conda activate especialidadmachinelearning
````

> El archivo `environment.yml` se genera autom√°ticamente por el script `init_project.sh`.

### ‚úÖ Opci√≥n 2: Sin Conda (instalar manualmente)

```bash
pip install numpy matplotlib
```

---

## üöÄ Uso

### ‚ö° Crear la estructura del proyecto

```bash
chmod +x init_project.sh
./init_project.sh
```

Esto:

* Genera carpetas (`src`, `scripts`, `outputs`, `notebooks`)
* Crea un `main.py` con l√≥gica inicial
* Crea `environment.yml`
* Crea m√≥dulos `.py` b√°sicos para iniciar

### ‚ñ∂Ô∏è Ejecutar el an√°lisis principal

```bash
python scripts/main.py
```

Esto ejecutar√° el entrenamiento con GD y SGD y guardar√° el gr√°fico comparativo en `outputs/comparacion_gd_sgd.png`.

---

## üìì Jupyter Notebook

Un notebook con la l√≥gica del proyecto puede ser generado autom√°ticamente en `notebooks/` si se implementa `crear_notebook.py`.

---

## üß† Reflexi√≥n

Este proyecto muestra c√≥mo la elecci√≥n del m√©todo de optimizaci√≥n y la tasa de aprendizaje afectan:

* la estabilidad del entrenamiento,
* la velocidad de convergencia,
* y la precisi√≥n de los par√°metros finales.

Esto es fundamental en Machine Learning, donde entrenar modelos eficientes depende de una buena estrategia de optimizaci√≥n.

---

# üìà Comparaci√≥n de M√©todos de Optimizaci√≥n para Regresi√≥n Lineal

Este proyecto implementa, compara y analiza diferentes enfoques para resolver un problema de regresi√≥n lineal simple, utilizando tanto m√©todos anal√≠ticos como iterativos (descenso de gradiente y su variante estoc√°stica).


---

## üìä Metodolog√≠a

1. **Generaci√≥n de Datos**

   * Se generan 100 puntos seg√∫n:

     $$
     y = 4 + 3x + \epsilon, \quad \epsilon \sim \mathcal{N}(0, 1)
     $$

2. **Resoluci√≥n del Modelo**

   * **C√°lculo Cerrado**:

     $$
     \beta = (X^T X)^{-1} X^T y
     $$
   * Validaci√≥n mediante manejo de excepciones si la matriz es singular.

3. **Optimizaci√≥n Iterativa**:

   * **GD**: utiliza todo el conjunto de datos por iteraci√≥n.
   * **SGD**: actualiza con una muestra por iteraci√≥n.

4. **Visualizaci√≥n**:

   * Evoluci√≥n del costo (MSE) a lo largo de las iteraciones.
   * Trayectoria de los par√°metros `w` y `b`.

---

## üìâ Resultados Obtenidos

### ‚ö° C√°lculo Cerrado

* Par√°metros anal√≠ticos:

  $$
  w = 2.9540,\quad b = 4.2151
  $$

### üîÅ Gradient Descent (GD)

* Par√°metros finales:

  $$
  w = 3.1397,\quad b = 3.0072
  $$

### üîÅ Stochastic Gradient Descent (SGD)

* Par√°metros finales:

  $$
  w = 3.0165,\quad b = 3.9912
  $$

---

## üì∑ Visualizaci√≥n de Resultados

üìç Output guardado en [`outputs/comparacion_gd_sgd.png`](outputs/comparacion_gd_sgd.png)

![Comparaci√≥n GD vs SGD](outputs/comparacion_gd_sgd.png)

* La curva de costo de **GD** es m√°s suave, pero m√°s lenta en converger.
* **SGD** desciende r√°pidamente al inicio, pero con mayor variabilidad.
* Ambos m√©todos se aproximan al modelo anal√≠tico, validando su correcto funcionamiento.

---

## üìå Reflexi√≥n Final

* **GD** y **SGD** convergen hacia la soluci√≥n √≥ptima, aunque con diferentes trayectorias y eficiencia.
* **SGD** puede ser m√°s adecuado en grandes vol√∫menes de datos o en entornos en l√≠nea.
* El **c√°lculo cerrado** es ideal para problemas peque√±os y bien condicionados.
* La **tasa de aprendizaje (learning rate)** juega un rol clave en la convergencia y debe ajustarse cuidadosamente.

---

## üõ°Ô∏è Manejo de Errores

Se definen excepciones personalizadas para:

* `MatrizSingularError`: si la matriz $X^T X$ no puede invertirse.
* `ParametrosNoConvergentesError`: si el costo no mejora significativamente.
* `DatosInsuficientesError`: si los datos no son suficientes para entrenamiento.

---

## ‚úÖ Validaci√≥n del Proyecto con Tests Automatizados

Este proyecto incluye un conjunto de pruebas para validar el correcto funcionamiento de las excepciones personalizadas definidas en `src/excepciones.py`. Estas pruebas aseguran que el sistema responde adecuadamente ante situaciones espec√≠ficas como:

* **Singularidad de la matriz** en la regresi√≥n lineal cerrada.
* **Falta de convergencia** en algoritmos iterativos.
* **Datos insuficientes** para entrenar un modelo.

### üìÅ Ubicaci√≥n de los tests

Los tests est√°n ubicados en el directorio:

```
tests/test_excepciones.py
```

### ‚ñ∂Ô∏è Ejecuci√≥n de los tests

Desde la ra√≠z del proyecto, ejecuta el siguiente comando:

```bash
pytest tests/test_excepciones.py -v
```

### ‚úÖ Resultado esperado

Una ejecuci√≥n exitosa mostrar√° una salida como la siguiente:

```
==================================================== test session starts =====================================================
platform linux -- Python 3.11.6, pytest-7.1.3, pluggy-1.0.0 -- /usr/bin/python3
cachedir: .pytest_cache
rootdir: /home/mparraf/myprojects/ESpecialidadMachineLearning/Modulo3EvalMod_MarcoParra
collected 3 items                                                                                                            

tests/test_excepciones.py::test_matriz_singular_error PASSED                                                           [ 33%]
tests/test_excepciones.py::test_datos_insuficientes_error PASSED                                                       [ 66%]
tests/test_excepciones.py::test_parametros_no_convergentes_error PASSED                                                [100%]

===================================================== 3 passed in 0.05s =====================================================
```

### üß™ ¬øQu√© valida cada test?

| Test                                    | Descripci√≥n                                                                                   |
| --------------------------------------- | --------------------------------------------------------------------------------------------- |
| `test_matriz_singular_error`            | Verifica que se lanza una excepci√≥n cuando la matriz $X^TX$ no puede invertirse.              |
| `test_datos_insuficientes_error`        | Simula expl√≠citamente la falta de datos y espera que se levante la excepci√≥n correspondiente. |
| `test_parametros_no_convergentes_error` | Fuerza una divergencia en Gradient Descent con una tasa de aprendizaje exagerada.             |


---

## üßë‚Äçüíª Autor

**Marco Antonio Fern√°ndez Parra**
Especialidad en Machine Learning ‚Äì M√≥dulo 3
Proyecto Evaluaci√≥n Modular ‚Äì Regresi√≥n Lineal
Junio 2025

---



